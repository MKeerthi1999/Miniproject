{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNM6wBl3AGt38WbAzpfPQne"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRwF5C9tRJ_G",
        "outputId": "d9b557ed-6e0d-45f1-a2d6-0279b804306e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "from typing import List, Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!pip install torchinfo\n",
        "import torchinfo\n",
        "\n",
        "torch.manual_seed(0)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader(dataset, transform=None, val_split=0.25, batch_size=64, num_workers=2):\n",
        "    train_set = dataset('./data', train=True,  download=True, transform=transform)\n",
        "    test_set  = dataset('./data', train=False, download=True, transform=transform)\n",
        "\n",
        "    train_set, val_set = torch.utils.data.random_split(train_set, [1-val_split, val_split])\n",
        "\n",
        "    train = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True,  num_workers=num_workers)\n",
        "    val   = torch.utils.data.DataLoader(val_set,   batch_size=batch_size, shuffle=True,  num_workers=num_workers)\n",
        "    test  = torch.utils.data.DataLoader(test_set,  batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "    return (train, val, test)"
      ],
      "metadata": {
        "id": "XzMQR5wZmjXk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, input_shape: Tuple[int], cnn_out_features: List[int]):\n",
        "        super().__init__()\n",
        "\n",
        "        self.cnn_layers = nn.ModuleList()\n",
        "        shape = list(input_shape)\n",
        "        prev_nf = input_shape[0]\n",
        "\n",
        "        for curr_nf in cnn_out_features:\n",
        "            self.cnn_layers.append(nn.Sequential(\n",
        "                nn.Conv2d(prev_nf, curr_nf, kernel_size=3, padding='same'),\n",
        "                nn.MaxPool2d(2)\n",
        "            ))\n",
        "            prev_nf = curr_nf\n",
        "\n",
        "            shape[0] = curr_nf\n",
        "            shape[1] = int(shape[1] / 2)\n",
        "            shape[2] = int(shape[2] / 2)\n",
        "\n",
        "        self.input_shape = input_shape\n",
        "        self.output_shape = (shape[0], shape[1], shape[2])\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        for layer in self.cnn_layers:\n",
        "            x = layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "PWMo8zwVmnwv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassRegressor(nn.Module):\n",
        "    def __init__(self, input_shape: Tuple[int], output_shape: int, fnn_out_features: List[int]):\n",
        "        super().__init__()\n",
        "\n",
        "        if isinstance(input_shape, tuple):\n",
        "            in_features = 1\n",
        "            for x in input_shape:\n",
        "                in_features *= x\n",
        "        else:\n",
        "            in_features = input_shape\n",
        "\n",
        "        self.fnn_layers = nn.ModuleList()\n",
        "        prev_nf = in_features\n",
        "\n",
        "        for curr_nf in fnn_out_features:\n",
        "            self.fnn_layers.append(nn.Sequential(\n",
        "                nn.Linear(prev_nf, curr_nf),\n",
        "                nn.ReLU()\n",
        "            ))\n",
        "            prev_nf = curr_nf\n",
        "\n",
        "        self.op_layer = nn.Linear(prev_nf, output_shape)\n",
        "\n",
        "        self.in_features = in_features\n",
        "        self.out_features = output_shape\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        for layer in self.fnn_layers:\n",
        "            x = layer(x)\n",
        "        x = self.op_layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "vd88z4dJmzfL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KRegressor(nn.Module):\n",
        "    def __init__(self, input_shape: int, hidden_size: int):\n",
        "        super().__init__()\n",
        "\n",
        "        if isinstance(input_shape, tuple):\n",
        "            in_features = 1\n",
        "            for x in input_shape:\n",
        "                in_features *= x\n",
        "        else:\n",
        "            in_features = input_shape\n",
        "\n",
        "        self.projection = nn.Linear(in_features, hidden_size)\n",
        "        self.transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=hidden_size,\n",
        "                nhead=1\n",
        "            ),\n",
        "            num_layers=1\n",
        "        )\n",
        "        self.output_layer = nn.Sequential(\n",
        "            nn.Linear(hidden_size, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.projection(x)\n",
        "        z = self.transformer(x)[0, :]\n",
        "        k = self.output_layer(z)\n",
        "        return k"
      ],
      "metadata": {
        "id": "8EhMeJ4Lm8vy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DimensionReducer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features: int,\n",
        "        hidden_size: int,\n",
        "        beta: float = 5.0,\n",
        "        esp:  float = 1e-8\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.beta = beta\n",
        "        self.esp = esp\n",
        "        self.k_regressor = KRegressor(in_features, hidden_size)\n",
        "        self.k = nn.Parameter(torch.randn(1))\n",
        "        self.k.requires_grad = True\n",
        "\n",
        "    def forward(self, xs: torch.Tensor) -> torch.Tensor:\n",
        "        kd = min(xs.shape[0], xs.shape[1])\n",
        "        # ks = self.k_regressor(xs)\n",
        "        ks = F.sigmoid(self.k)\n",
        "\n",
        "        xs = xs - torch.mean(xs, dim=0)\n",
        "        # xs = xs + self.esp\n",
        "        us, ss, vhs = torch.linalg.svd(xs, full_matrices=False)\n",
        "\n",
        "        i = torch.arange(kd, device=xs.device)\n",
        "        ws = torch.sigmoid(-self.beta*(i - ks*kd))\n",
        "\n",
        "        ss1 = torch.diag(ss * ws)\n",
        "        xs = torch.mm(torch.mm(us, ss1), vhs)\n",
        "\n",
        "        return (xs, ks)"
      ],
      "metadata": {
        "id": "5ab8tLVQnE_X"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_shape:      Tuple[int],\n",
        "        output_shape:     int,\n",
        "        cnn_out_features: List[int],\n",
        "        fnn_out_features: List[int]\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.feature_extractor = FeatureExtractor(input_shape, cnn_out_features)\n",
        "        self.class_regressor   = ClassRegressor(self.feature_extractor.output_shape, output_shape, fnn_out_features)\n",
        "        self.dimension_reducer = DimensionReducer(self.feature_extractor.output_shape, hidden_size=128)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x, k = self.dimension_reducer(x)\n",
        "        x = self.class_regressor(x)\n",
        "        return (x, k)"
      ],
      "metadata": {
        "id": "ZiGscgBlnJkw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(\n",
        "    losses: List[np.ndarray],\n",
        "    labels: List[str] = None,\n",
        "    ylabel: str = '',\n",
        "    xlabel: str = '',\n",
        "    title:  str = ''\n",
        "):\n",
        "    if labels is None:\n",
        "        labels = [''] * len(losses)\n",
        "    for loss, label in zip(losses, labels):\n",
        "        plt.plot(loss, label=label)\n",
        "    plt.legend()\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "JJwC2bppnVOX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_c = 1e-3\n",
        "batch_size = 128\n",
        "model_save_path = 'best_model.pt'\n",
        "\n",
        "num_epochs = 50\n",
        "checkpoint = 20\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.5, 0.5)\n",
        "])\n",
        "\n",
        "train_s, val_s, test_s = create_dataloader(\n",
        "    torchvision.datasets.MNIST,\n",
        "    transform=transform,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "train_t, val_t, test_t = create_dataloader(\n",
        "    torchvision.datasets.USPS,\n",
        "    transform=transforms.Compose([transform, transforms.Resize((28, 28))]),\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PdA79NVnZ-n",
        "outputId": "c1a9976b-791b-43b6-aa7a-0159a7e28731"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 54.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 2.11MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 13.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.56MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/usps.bz2 to ./data/usps.bz2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.58M/6.58M [00:01<00:00, 3.39MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/usps.t.bz2 to ./data/usps.t.bz2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.83M/1.83M [00:01<00:00, 1.35MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model_c, dataloader, cls_loss_fn, mode=None):\n",
        "    model_c.eval()\n",
        "    cls_losses = []\n",
        "    accuracy   = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (x, y_true) in enumerate(dataloader):\n",
        "            x = x.to(device)\n",
        "            y_true = y_true.to(device)\n",
        "\n",
        "            y_pred, _ = model_c(x)\n",
        "            loss = cls_loss_fn(y_pred, y_true)\n",
        "\n",
        "            cls_losses += [loss.item()]\n",
        "            y_pred1 = torch.max(y_pred, dim=1)[1]\n",
        "            accuracy += torch.sum(y_pred1 == y_true).item()\n",
        "\n",
        "    cls_loss = np.mean(cls_losses)\n",
        "    accuracy /= len(dataloader.dataset)\n",
        "\n",
        "    if mode is not None:\n",
        "        print('{} -> cls_loss: {:.6f}\\taccuracy: {:.4f}%'.format(\n",
        "            mode,\n",
        "            cls_loss,\n",
        "            accuracy * 100\n",
        "        ))\n",
        "    return (cls_loss, accuracy)"
      ],
      "metadata": {
        "id": "CWdufhHUngbi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(xs, xt, ys_true, alpha, gamma):\n",
        "    N = xs.shape[0]\n",
        "\n",
        "    ys_pred, ks = classifier(xs)\n",
        "\n",
        "    cls_loss = cls_loss_fn(ys_pred, ys_true)\n",
        "    k_loss = ks**2\n",
        "\n",
        "    # alignment to target\n",
        "    kd = min(xs.shape[0], xs.shape[1])\n",
        "\n",
        "    xt = classifier.feature_extractor(xt)\n",
        "    xt = torch.flatten(xt, start_dim=1)\n",
        "\n",
        "    xt = xt - torch.mean(xt, dim=0)\n",
        "    # xs = xs + self.esp\n",
        "    ut, st, vht = torch.linalg.svd(xt, full_matrices=False)\n",
        "\n",
        "    i = torch.arange(kd, device=xs.device)\n",
        "    beta = classifier.dimension_reducer.beta\n",
        "    wt = torch.sigmoid(-beta*(i - ks*kd))\n",
        "    wt = 1 - wt\n",
        "\n",
        "    st1 = torch.diag(st * wt)\n",
        "    xt = torch.mm(torch.mm(ut, st1), vht)\n",
        "\n",
        "    yt_pred = classifier.class_regressor(xt)\n",
        "    yt_true = torch.zeros(N, classifier.class_regressor.out_features, device=device)\n",
        "\n",
        "    lat_loss = F.mse_loss(yt_pred, yt_true)\n",
        "\n",
        "    loss = cls_loss + alpha*ks + gamma*lat_loss\n",
        "\n",
        "    optimizer_c.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer_c.step()\n",
        "\n",
        "    return (\n",
        "        loss.item(),\n",
        "        cls_loss.item(),\n",
        "        k_loss.item(),\n",
        "        ks.item(),\n",
        "        lat_loss.item()\n",
        "    )"
      ],
      "metadata": {
        "id": "vfE_PoSfnmay"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    global classifier, dimension_reducer\n",
        "    global cls_loss_fn\n",
        "    global optimizer_c\n",
        "    global loss_labels_train, loss_labels_val\n",
        "\n",
        "    classifier = MyModel(\n",
        "        input_shape=(1, 28, 28),\n",
        "        output_shape=10,\n",
        "        cnn_out_features=[16, 32, 64],\n",
        "        fnn_out_features=[128, 64],\n",
        "    ).to(device)\n",
        "\n",
        "    dimension_reducer = DimensionReducer(\n",
        "        classifier.class_regressor.in_features,\n",
        "        hidden_size=128\n",
        "    ).to(device)\n",
        "\n",
        "    print(torchinfo.summary(classifier, input_size=(batch_size, 1, 28, 28)))\n",
        "\n",
        "    cls_loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer_c = torch.optim.Adam(classifier.parameters(), lr=lr_c)\n",
        "\n",
        "    all_loss = np.zeros((num_epochs, 5))\n",
        "    loss_labels_train = ['loss', 'cls_loss', 'k_loss', 'k', 'lat_loss']\n",
        "\n",
        "    all_loss_val = np.zeros((num_epochs, 4))\n",
        "    all_loss_test = np.zeros((1, 4))\n",
        "    loss_labels_val = ['cls_loss_s', 'accuracy_s', 'cls_loss_t', 'accuracy_t']\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_k = 1\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1} --------')\n",
        "\n",
        "        classifier.train()\n",
        "\n",
        "        len_dataloader = min(len(train_s), len(train_t))\n",
        "        iter_s = iter(train_s)\n",
        "        iter_t = iter(train_t)\n",
        "\n",
        "        avg_loss = np.zeros(all_loss.shape[1])\n",
        "\n",
        "        for batch_idx in range(len_dataloader):\n",
        "            p = float(batch_idx + epoch*len_dataloader) / (num_epochs*len_dataloader)\n",
        "            # alpha = 2 / (1 + np.exp(-10 * p)) - 1\n",
        "            alpha = 1e-3\n",
        "            gamma = 1e-3\n",
        "\n",
        "            # if epoch % 5 == 0 and epoch != 0:\n",
        "            #     for param in classifier.feature_extractor.parameters():\n",
        "            #         param.requires_grad = False\n",
        "            #     for param in classifier.dimension_reducer.parameters():\n",
        "            #         param.requires_grad = False\n",
        "            # else:\n",
        "            #     for param in classifier.feature_extractor.parameters():\n",
        "            #         param.requires_grad = True\n",
        "            #     for param in classifier.dimension_reducer.parameters():         #         param.requires_grad = True\n",
        "\n",
        "            data_s = next(iter_s)\n",
        "            data_t = next(iter_t)\n",
        "\n",
        "            xs, ys_true = data_s\n",
        "            xt, yt_true = data_t\n",
        "            if xs.shape[0] != xt.shape[0]:\n",
        "                continue\n",
        "\n",
        "            xs = xs.to(device)\n",
        "            xt = xt.to(device)\n",
        "            ys_true = ys_true.to(device)\n",
        "            yt_true = yt_true.to(device)\n",
        "\n",
        "            losses = train_step(xs, xt, ys_true, alpha, gamma)\n",
        "            avg_loss += losses\n",
        "\n",
        "            if checkpoint is not None and batch_idx % checkpoint == 0:\n",
        "                print('Train -> [{:>5}/{:>5} ({:.0f}%)]'.format(\n",
        "                        batch_idx * batch_size,\n",
        "                        len_dataloader * batch_size,\n",
        "                        batch_idx / len_dataloader * 100\n",
        "                    ),\n",
        "                    end='\\t'\n",
        "                )\n",
        "                for loss, label in zip(losses, loss_labels_train):\n",
        "                    print(f'{label}: {loss:.6f}', end='\\t')\n",
        "                print('')\n",
        "\n",
        "        avg_loss = avg_loss / len_dataloader\n",
        "        all_loss[epoch] = losses\n",
        "\n",
        "        val_losses_s = evaluate(classifier, val_s, cls_loss_fn, mode='Validation (source)')\n",
        "        val_losses_t = evaluate(classifier, val_t, cls_loss_fn, mode='Validation (target)')\n",
        "\n",
        "        all_loss_val[epoch] = val_losses_s + val_losses_t\n",
        "\n",
        "        val_loss = val_losses_t[0]\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            torch.save(classifier.state_dict(), model_save_path)\n",
        "            best_k = avg_loss[-1]\n",
        "            best_val_loss = val_loss\n",
        "            print(f'Best model updated and saved at \"{model_save_path}\"')\n",
        "\n",
        "    classifier.load_state_dict(torch.load(model_save_path))\n",
        "    test_loss_s = evaluate(classifier, test_s, cls_loss_fn, mode='Test (source)')\n",
        "    test_loss_t = evaluate(classifier, test_t, cls_loss_fn, mode='Test (target)')\n",
        "\n",
        "    all_loss_test = test_loss_s + test_loss_t\n",
        "\n",
        "    return (all_loss, all_loss_val, all_loss_test)\n"
      ],
      "metadata": {
        "id": "WDSR9CmOnw31"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_loss_train = []\n",
        "all_loss_val   = []\n",
        "all_loss_test  = []\n",
        "for i in range(5):\n",
        "    loss_train, loss_val, loss_test = main()\n",
        "    all_loss_train.append(loss_train)\n",
        "    all_loss_val.append(loss_val)\n",
        "    all_loss_test.append(loss_test)\n",
        "\n",
        "all_loss_train = np.array(all_loss_train)\n",
        "all_loss_val   = np.array(all_loss_val)\n",
        "all_loss_test  = np.array(all_loss_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFzAHUk3oE2B",
        "outputId": "da7900c7-66f5-4bc4-b0a0-0de8062cf21d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "MyModel                                  [128, 10]                 --\n",
            "├─FeatureExtractor: 1-1                  [128, 64, 3, 3]           --\n",
            "│    └─ModuleList: 2-1                   --                        --\n",
            "│    │    └─Sequential: 3-1              [128, 16, 14, 14]         160\n",
            "│    │    └─Sequential: 3-2              [128, 32, 7, 7]           4,640\n",
            "│    │    └─Sequential: 3-3              [128, 64, 3, 3]           18,496\n",
            "├─DimensionReducer: 1-2                  [128, 576]                667,010\n",
            "├─ClassRegressor: 1-3                    [128, 10]                 --\n",
            "│    └─ModuleList: 2-2                   --                        --\n",
            "│    │    └─Sequential: 3-4              [128, 128]                73,856\n",
            "│    │    └─Sequential: 3-5              [128, 64]                 8,256\n",
            "│    └─Linear: 2-3                       [128, 10]                 650\n",
            "==========================================================================================\n",
            "Total params: 773,068\n",
            "Trainable params: 773,068\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 259.07\n",
            "==========================================================================================\n",
            "Input size (MB): 0.40\n",
            "Forward/backward pass size (MB): 22.69\n",
            "Params size (MB): 0.42\n",
            "Estimated Total Size (MB): 23.51\n",
            "==========================================================================================\n",
            "Epoch 1 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 2.308138\tcls_loss: 2.307955\tk_loss: 0.032407\tk: 0.180019\tlat_loss: 0.002849\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 1.392507\tcls_loss: 1.392256\tk_loss: 0.032610\tk: 0.180583\tlat_loss: 0.069661\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.415428\tcls_loss: 0.414687\tk_loss: 0.033560\tk: 0.183194\tlat_loss: 0.557665\t\n",
            "Validation (source) -> cls_loss: 0.387058\taccuracy: 88.9467%\n",
            "Validation (target) -> cls_loss: 1.030294\taccuracy: 64.5993%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 2 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.399114\tcls_loss: 0.398389\tk_loss: 0.033660\tk: 0.183466\tlat_loss: 0.540920\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.192882\tcls_loss: 0.192032\tk_loss: 0.034224\tk: 0.184996\tlat_loss: 0.664356\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.179098\tcls_loss: 0.178371\tk_loss: 0.034886\tk: 0.186779\tlat_loss: 0.540211\t\n",
            "Validation (source) -> cls_loss: 0.195591\taccuracy: 94.2267%\n",
            "Validation (target) -> cls_loss: 0.925949\taccuracy: 68.2766%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 3 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.168632\tcls_loss: 0.167909\tk_loss: 0.034895\tk: 0.186802\tlat_loss: 0.536054\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.137934\tcls_loss: 0.137175\tk_loss: 0.034886\tk: 0.186777\tlat_loss: 0.572156\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.078774\tcls_loss: 0.077954\tk_loss: 0.035219\tk: 0.187667\tlat_loss: 0.631723\t\n",
            "Validation (source) -> cls_loss: 0.142567\taccuracy: 95.7267%\n",
            "Validation (target) -> cls_loss: 0.966933\taccuracy: 66.8496%\n",
            "Epoch 4 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.138911\tcls_loss: 0.138080\tk_loss: 0.035278\tk: 0.187823\tlat_loss: 0.642623\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.077196\tcls_loss: 0.076341\tk_loss: 0.035569\tk: 0.188598\tlat_loss: 0.665986\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.062977\tcls_loss: 0.062077\tk_loss: 0.035981\tk: 0.189686\tlat_loss: 0.710283\t\n",
            "Validation (source) -> cls_loss: 0.119933\taccuracy: 96.4600%\n",
            "Validation (target) -> cls_loss: 0.933074\taccuracy: 69.3743%\n",
            "Epoch 5 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.098676\tcls_loss: 0.097805\tk_loss: 0.036017\tk: 0.189781\tlat_loss: 0.680784\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.093698\tcls_loss: 0.092809\tk_loss: 0.036247\tk: 0.190387\tlat_loss: 0.698565\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.129432\tcls_loss: 0.128535\tk_loss: 0.036551\tk: 0.191183\tlat_loss: 0.706323\t\n",
            "Validation (source) -> cls_loss: 0.111078\taccuracy: 96.5133%\n",
            "Validation (target) -> cls_loss: 1.119516\taccuracy: 70.1427%\n",
            "Epoch 6 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.097328\tcls_loss: 0.096409\tk_loss: 0.036588\tk: 0.191281\tlat_loss: 0.727023\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.079444\tcls_loss: 0.078530\tk_loss: 0.037057\tk: 0.192503\tlat_loss: 0.721743\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.043807\tcls_loss: 0.042843\tk_loss: 0.037416\tk: 0.193431\tlat_loss: 0.770127\t\n",
            "Validation (source) -> cls_loss: 0.090663\taccuracy: 97.1867%\n",
            "Validation (target) -> cls_loss: 0.912769\taccuracy: 72.5576%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 7 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.031279\tcls_loss: 0.030292\tk_loss: 0.037443\tk: 0.193501\tlat_loss: 0.793519\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.039710\tcls_loss: 0.038673\tk_loss: 0.037738\tk: 0.194262\tlat_loss: 0.842552\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.089676\tcls_loss: 0.088735\tk_loss: 0.038240\tk: 0.195550\tlat_loss: 0.746092\t\n",
            "Validation (source) -> cls_loss: 0.091970\taccuracy: 97.1800%\n",
            "Validation (target) -> cls_loss: 0.844275\taccuracy: 76.9484%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 8 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.057618\tcls_loss: 0.056620\tk_loss: 0.038297\tk: 0.195695\tlat_loss: 0.802622\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.042132\tcls_loss: 0.041104\tk_loss: 0.038602\tk: 0.196474\tlat_loss: 0.830657\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.092391\tcls_loss: 0.091387\tk_loss: 0.038833\tk: 0.197060\tlat_loss: 0.806975\t\n",
            "Validation (source) -> cls_loss: 0.078129\taccuracy: 97.6533%\n",
            "Validation (target) -> cls_loss: 0.945049\taccuracy: 70.8562%\n",
            "Epoch 9 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.067328\tcls_loss: 0.066431\tk_loss: 0.038855\tk: 0.197116\tlat_loss: 0.700240\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.071014\tcls_loss: 0.070047\tk_loss: 0.039082\tk: 0.197692\tlat_loss: 0.769733\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.049020\tcls_loss: 0.047934\tk_loss: 0.039523\tk: 0.198804\tlat_loss: 0.887309\t\n",
            "Validation (source) -> cls_loss: 0.080214\taccuracy: 97.5467%\n",
            "Validation (target) -> cls_loss: 0.980631\taccuracy: 73.1065%\n",
            "Epoch 10 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.090907\tcls_loss: 0.089843\tk_loss: 0.039558\tk: 0.198891\tlat_loss: 0.865199\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.027451\tcls_loss: 0.026493\tk_loss: 0.039723\tk: 0.199305\tlat_loss: 0.758378\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.090890\tcls_loss: 0.089902\tk_loss: 0.039832\tk: 0.199579\tlat_loss: 0.788074\t\n",
            "Validation (source) -> cls_loss: 0.074414\taccuracy: 97.7533%\n",
            "Validation (target) -> cls_loss: 0.799702\taccuracy: 76.1800%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 11 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.019587\tcls_loss: 0.018577\tk_loss: 0.039835\tk: 0.199587\tlat_loss: 0.810228\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.045536\tcls_loss: 0.044685\tk_loss: 0.039944\tk: 0.199859\tlat_loss: 0.651195\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.045979\tcls_loss: 0.045022\tk_loss: 0.040114\tk: 0.200284\tlat_loss: 0.756206\t\n",
            "Validation (source) -> cls_loss: 0.070076\taccuracy: 97.8600%\n",
            "Validation (target) -> cls_loss: 0.883312\taccuracy: 74.6981%\n",
            "Epoch 12 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.091698\tcls_loss: 0.090822\tk_loss: 0.040145\tk: 0.200361\tlat_loss: 0.676156\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.048976\tcls_loss: 0.047904\tk_loss: 0.040477\tk: 0.201188\tlat_loss: 0.870826\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.117735\tcls_loss: 0.116776\tk_loss: 0.040850\tk: 0.202115\tlat_loss: 0.756722\t\n",
            "Validation (source) -> cls_loss: 0.062783\taccuracy: 98.2200%\n",
            "Validation (target) -> cls_loss: 0.961382\taccuracy: 71.7892%\n",
            "Epoch 13 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.012821\tcls_loss: 0.011936\tk_loss: 0.040927\tk: 0.202305\tlat_loss: 0.683319\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.039985\tcls_loss: 0.039015\tk_loss: 0.041231\tk: 0.203054\tlat_loss: 0.766453\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.076797\tcls_loss: 0.075838\tk_loss: 0.041774\tk: 0.204388\tlat_loss: 0.754688\t\n",
            "Validation (source) -> cls_loss: 0.065079\taccuracy: 98.0933%\n",
            "Validation (target) -> cls_loss: 0.826700\taccuracy: 74.5335%\n",
            "Epoch 14 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.034981\tcls_loss: 0.033994\tk_loss: 0.041829\tk: 0.204521\tlat_loss: 0.782348\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.075389\tcls_loss: 0.074421\tk_loss: 0.042082\tk: 0.205140\tlat_loss: 0.762729\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.079876\tcls_loss: 0.078794\tk_loss: 0.042262\tk: 0.205577\tlat_loss: 0.876774\t\n",
            "Validation (source) -> cls_loss: 0.073896\taccuracy: 97.8333%\n",
            "Validation (target) -> cls_loss: 1.036282\taccuracy: 73.1614%\n",
            "Epoch 15 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.078370\tcls_loss: 0.077261\tk_loss: 0.042278\tk: 0.205616\tlat_loss: 0.903601\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.031814\tcls_loss: 0.030957\tk_loss: 0.042608\tk: 0.206417\tlat_loss: 0.650712\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.057978\tcls_loss: 0.056893\tk_loss: 0.042752\tk: 0.206765\tlat_loss: 0.878107\t\n",
            "Validation (source) -> cls_loss: 0.071771\taccuracy: 97.8133%\n",
            "Validation (target) -> cls_loss: 1.059259\taccuracy: 71.2404%\n",
            "Epoch 16 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.040231\tcls_loss: 0.039163\tk_loss: 0.042731\tk: 0.206714\tlat_loss: 0.861801\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.021608\tcls_loss: 0.020797\tk_loss: 0.042636\tk: 0.206486\tlat_loss: 0.604630\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.027654\tcls_loss: 0.026795\tk_loss: 0.042391\tk: 0.205890\tlat_loss: 0.653483\t\n",
            "Validation (source) -> cls_loss: 0.064429\taccuracy: 98.0733%\n",
            "Validation (target) -> cls_loss: 0.974625\taccuracy: 70.0878%\n",
            "Epoch 17 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.025181\tcls_loss: 0.024273\tk_loss: 0.042395\tk: 0.205900\tlat_loss: 0.702303\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.030034\tcls_loss: 0.029155\tk_loss: 0.042406\tk: 0.205928\tlat_loss: 0.673240\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.033631\tcls_loss: 0.032778\tk_loss: 0.042467\tk: 0.206074\tlat_loss: 0.646792\t\n",
            "Validation (source) -> cls_loss: 0.073837\taccuracy: 97.7667%\n",
            "Validation (target) -> cls_loss: 0.922735\taccuracy: 73.4907%\n",
            "Epoch 18 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.044500\tcls_loss: 0.043615\tk_loss: 0.042527\tk: 0.206220\tlat_loss: 0.678593\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.061315\tcls_loss: 0.060459\tk_loss: 0.043029\tk: 0.207436\tlat_loss: 0.647713\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.070945\tcls_loss: 0.070160\tk_loss: 0.043211\tk: 0.207871\tlat_loss: 0.576766\t\n",
            "Validation (source) -> cls_loss: 0.064943\taccuracy: 98.0333%\n",
            "Validation (target) -> cls_loss: 0.876392\taccuracy: 72.9418%\n",
            "Epoch 19 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.013616\tcls_loss: 0.012757\tk_loss: 0.043245\tk: 0.207955\tlat_loss: 0.651136\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.170779\tcls_loss: 0.169946\tk_loss: 0.043391\tk: 0.208305\tlat_loss: 0.624697\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.005078\tcls_loss: 0.004218\tk_loss: 0.043941\tk: 0.209622\tlat_loss: 0.650953\t\n",
            "Validation (source) -> cls_loss: 0.065453\taccuracy: 98.1000%\n",
            "Validation (target) -> cls_loss: 0.777827\taccuracy: 75.4665%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 20 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.016789\tcls_loss: 0.015942\tk_loss: 0.044002\tk: 0.209767\tlat_loss: 0.637680\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.121114\tcls_loss: 0.120214\tk_loss: 0.044459\tk: 0.210852\tlat_loss: 0.688669\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.100503\tcls_loss: 0.099458\tk_loss: 0.044656\tk: 0.211320\tlat_loss: 0.833413\t\n",
            "Validation (source) -> cls_loss: 0.060891\taccuracy: 98.2067%\n",
            "Validation (target) -> cls_loss: 0.840106\taccuracy: 76.0703%\n",
            "Epoch 21 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.069384\tcls_loss: 0.068432\tk_loss: 0.044693\tk: 0.211406\tlat_loss: 0.739984\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.022166\tcls_loss: 0.021328\tk_loss: 0.045074\tk: 0.212306\tlat_loss: 0.626368\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.046419\tcls_loss: 0.045333\tk_loss: 0.045240\tk: 0.212697\tlat_loss: 0.872910\t\n",
            "Validation (source) -> cls_loss: 0.060378\taccuracy: 98.3200%\n",
            "Validation (target) -> cls_loss: 0.948505\taccuracy: 72.8869%\n",
            "Epoch 22 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.034577\tcls_loss: 0.033530\tk_loss: 0.045198\tk: 0.212599\tlat_loss: 0.834384\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.062518\tcls_loss: 0.061654\tk_loss: 0.045357\tk: 0.212972\tlat_loss: 0.650451\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.025874\tcls_loss: 0.024870\tk_loss: 0.045723\tk: 0.213828\tlat_loss: 0.790105\t\n",
            "Validation (source) -> cls_loss: 0.064249\taccuracy: 98.1400%\n",
            "Validation (target) -> cls_loss: 0.787063\taccuracy: 73.0516%\n",
            "Epoch 23 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.040138\tcls_loss: 0.039133\tk_loss: 0.045754\tk: 0.213902\tlat_loss: 0.790492\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.021587\tcls_loss: 0.020669\tk_loss: 0.046371\tk: 0.215339\tlat_loss: 0.702501\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.016315\tcls_loss: 0.015426\tk_loss: 0.046809\tk: 0.216355\tlat_loss: 0.672612\t\n",
            "Validation (source) -> cls_loss: 0.062890\taccuracy: 98.2267%\n",
            "Validation (target) -> cls_loss: 0.738612\taccuracy: 75.6861%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 24 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.012901\tcls_loss: 0.011982\tk_loss: 0.046862\tk: 0.216476\tlat_loss: 0.702168\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.046810\tcls_loss: 0.045849\tk_loss: 0.046843\tk: 0.216432\tlat_loss: 0.744792\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.029826\tcls_loss: 0.028892\tk_loss: 0.046686\tk: 0.216070\tlat_loss: 0.718530\t\n",
            "Validation (source) -> cls_loss: 0.061958\taccuracy: 98.2200%\n",
            "Validation (target) -> cls_loss: 0.933329\taccuracy: 73.6553%\n",
            "Epoch 25 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.130001\tcls_loss: 0.129047\tk_loss: 0.046704\tk: 0.216111\tlat_loss: 0.738269\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.008196\tcls_loss: 0.007295\tk_loss: 0.046843\tk: 0.216433\tlat_loss: 0.684468\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.008349\tcls_loss: 0.007482\tk_loss: 0.047163\tk: 0.217170\tlat_loss: 0.649074\t\n",
            "Validation (source) -> cls_loss: 0.054933\taccuracy: 98.4200%\n",
            "Validation (target) -> cls_loss: 1.029866\taccuracy: 68.6059%\n",
            "Epoch 26 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.023430\tcls_loss: 0.022598\tk_loss: 0.047147\tk: 0.217135\tlat_loss: 0.614800\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.011628\tcls_loss: 0.010852\tk_loss: 0.047184\tk: 0.217218\tlat_loss: 0.558230\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.021988\tcls_loss: 0.021137\tk_loss: 0.048209\tk: 0.219566\tlat_loss: 0.630875\t\n",
            "Validation (source) -> cls_loss: 0.051116\taccuracy: 98.5400%\n",
            "Validation (target) -> cls_loss: 0.701227\taccuracy: 79.5829%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 27 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.069818\tcls_loss: 0.069004\tk_loss: 0.048295\tk: 0.219761\tlat_loss: 0.593579\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.056113\tcls_loss: 0.055294\tk_loss: 0.048923\tk: 0.221185\tlat_loss: 0.597501\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.029205\tcls_loss: 0.028307\tk_loss: 0.049265\tk: 0.221957\tlat_loss: 0.675937\t\n",
            "Validation (source) -> cls_loss: 0.054813\taccuracy: 98.4467%\n",
            "Validation (target) -> cls_loss: 0.867043\taccuracy: 72.8869%\n",
            "Epoch 28 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.022394\tcls_loss: 0.021517\tk_loss: 0.049307\tk: 0.222051\tlat_loss: 0.654839\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.011390\tcls_loss: 0.010553\tk_loss: 0.049630\tk: 0.222778\tlat_loss: 0.614236\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.013460\tcls_loss: 0.012636\tk_loss: 0.049984\tk: 0.223572\tlat_loss: 0.600032\t\n",
            "Validation (source) -> cls_loss: 0.072413\taccuracy: 98.0067%\n",
            "Validation (target) -> cls_loss: 0.868370\taccuracy: 70.5818%\n",
            "Epoch 29 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.045844\tcls_loss: 0.045050\tk_loss: 0.050023\tk: 0.223658\tlat_loss: 0.570412\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.011564\tcls_loss: 0.010699\tk_loss: 0.050472\tk: 0.224659\tlat_loss: 0.640516\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.035656\tcls_loss: 0.034863\tk_loss: 0.051072\tk: 0.225991\tlat_loss: 0.566851\t\n",
            "Validation (source) -> cls_loss: 0.057679\taccuracy: 98.3600%\n",
            "Validation (target) -> cls_loss: 0.893523\taccuracy: 70.3622%\n",
            "Epoch 30 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.064583\tcls_loss: 0.063777\tk_loss: 0.051119\tk: 0.226094\tlat_loss: 0.579659\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.010600\tcls_loss: 0.009740\tk_loss: 0.051687\tk: 0.227347\tlat_loss: 0.632547\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.005007\tcls_loss: 0.004188\tk_loss: 0.052791\tk: 0.229762\tlat_loss: 0.588818\t\n",
            "Validation (source) -> cls_loss: 0.048186\taccuracy: 98.6200%\n",
            "Validation (target) -> cls_loss: 0.717309\taccuracy: 76.8935%\n",
            "Epoch 31 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.016220\tcls_loss: 0.015423\tk_loss: 0.052861\tk: 0.229916\tlat_loss: 0.566684\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.035190\tcls_loss: 0.034226\tk_loss: 0.053172\tk: 0.230590\tlat_loss: 0.733831\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.025169\tcls_loss: 0.024253\tk_loss: 0.053111\tk: 0.230458\tlat_loss: 0.685388\t\n",
            "Validation (source) -> cls_loss: 0.052484\taccuracy: 98.5467%\n",
            "Validation (target) -> cls_loss: 0.794304\taccuracy: 73.9297%\n",
            "Epoch 32 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.047090\tcls_loss: 0.046233\tk_loss: 0.053110\tk: 0.230457\tlat_loss: 0.626884\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.019572\tcls_loss: 0.018773\tk_loss: 0.053512\tk: 0.231326\tlat_loss: 0.567130\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.030287\tcls_loss: 0.029460\tk_loss: 0.053859\tk: 0.232075\tlat_loss: 0.594871\t\n",
            "Validation (source) -> cls_loss: 0.049938\taccuracy: 98.6400%\n",
            "Validation (target) -> cls_loss: 0.844685\taccuracy: 71.1855%\n",
            "Epoch 33 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.021873\tcls_loss: 0.021092\tk_loss: 0.053902\tk: 0.232167\tlat_loss: 0.549246\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.027363\tcls_loss: 0.026485\tk_loss: 0.054277\tk: 0.232974\tlat_loss: 0.645069\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.011766\tcls_loss: 0.010810\tk_loss: 0.054481\tk: 0.233411\tlat_loss: 0.722455\t\n",
            "Validation (source) -> cls_loss: 0.048731\taccuracy: 98.5600%\n",
            "Validation (target) -> cls_loss: 0.955590\taccuracy: 70.5269%\n",
            "Epoch 34 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.007237\tcls_loss: 0.006376\tk_loss: 0.054493\tk: 0.233438\tlat_loss: 0.627640\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.063238\tcls_loss: 0.062391\tk_loss: 0.054675\tk: 0.233827\tlat_loss: 0.613418\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.013205\tcls_loss: 0.012330\tk_loss: 0.055297\tk: 0.235154\tlat_loss: 0.639692\t\n",
            "Validation (source) -> cls_loss: 0.046687\taccuracy: 98.7000%\n",
            "Validation (target) -> cls_loss: 0.681987\taccuracy: 78.7047%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 35 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.005565\tcls_loss: 0.004739\tk_loss: 0.055430\tk: 0.235436\tlat_loss: 0.590520\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.016705\tcls_loss: 0.015829\tk_loss: 0.056008\tk: 0.236661\tlat_loss: 0.638796\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.060790\tcls_loss: 0.059947\tk_loss: 0.056365\tk: 0.237412\tlat_loss: 0.605630\t\n",
            "Validation (source) -> cls_loss: 0.054332\taccuracy: 98.5467%\n",
            "Validation (target) -> cls_loss: 0.649631\taccuracy: 78.7596%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 36 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.029488\tcls_loss: 0.028705\tk_loss: 0.056417\tk: 0.237523\tlat_loss: 0.545014\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.055874\tcls_loss: 0.055176\tk_loss: 0.056897\tk: 0.238531\tlat_loss: 0.459261\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.022804\tcls_loss: 0.021909\tk_loss: 0.057614\tk: 0.240030\tlat_loss: 0.655056\t\n",
            "Validation (source) -> cls_loss: 0.053307\taccuracy: 98.4533%\n",
            "Validation (target) -> cls_loss: 0.979491\taccuracy: 70.5818%\n",
            "Epoch 37 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.047239\tcls_loss: 0.046416\tk_loss: 0.057637\tk: 0.240078\tlat_loss: 0.582693\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.079745\tcls_loss: 0.078983\tk_loss: 0.058233\tk: 0.241316\tlat_loss: 0.521019\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.016918\tcls_loss: 0.016097\tk_loss: 0.058578\tk: 0.242028\tlat_loss: 0.579635\t\n",
            "Validation (source) -> cls_loss: 0.051571\taccuracy: 98.5133%\n",
            "Validation (target) -> cls_loss: 0.856522\taccuracy: 74.6432%\n",
            "Epoch 38 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.041406\tcls_loss: 0.040544\tk_loss: 0.058600\tk: 0.242074\tlat_loss: 0.620551\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.014647\tcls_loss: 0.013812\tk_loss: 0.059016\tk: 0.242931\tlat_loss: 0.592299\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.024058\tcls_loss: 0.023164\tk_loss: 0.059027\tk: 0.242954\tlat_loss: 0.651250\t\n",
            "Validation (source) -> cls_loss: 0.049119\taccuracy: 98.6133%\n",
            "Validation (target) -> cls_loss: 0.747072\taccuracy: 74.9177%\n",
            "Epoch 39 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.076854\tcls_loss: 0.076019\tk_loss: 0.059087\tk: 0.243077\tlat_loss: 0.591718\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.032067\tcls_loss: 0.031308\tk_loss: 0.059322\tk: 0.243560\tlat_loss: 0.515464\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.003353\tcls_loss: 0.002568\tk_loss: 0.059573\tk: 0.244076\tlat_loss: 0.541509\t\n",
            "Validation (source) -> cls_loss: 0.046001\taccuracy: 98.6733%\n",
            "Validation (target) -> cls_loss: 0.773639\taccuracy: 76.2349%\n",
            "Epoch 40 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.029352\tcls_loss: 0.028537\tk_loss: 0.059586\tk: 0.244103\tlat_loss: 0.571770\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.014915\tcls_loss: 0.014158\tk_loss: 0.059731\tk: 0.244400\tlat_loss: 0.512832\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.014144\tcls_loss: 0.013425\tk_loss: 0.059626\tk: 0.244184\tlat_loss: 0.474780\t\n",
            "Validation (source) -> cls_loss: 0.050253\taccuracy: 98.6133%\n",
            "Validation (target) -> cls_loss: 0.654077\taccuracy: 79.6378%\n",
            "Epoch 41 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.006992\tcls_loss: 0.006275\tk_loss: 0.059623\tk: 0.244178\tlat_loss: 0.473179\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.008236\tcls_loss: 0.007418\tk_loss: 0.059587\tk: 0.244104\tlat_loss: 0.574261\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.015812\tcls_loss: 0.014906\tk_loss: 0.059561\tk: 0.244051\tlat_loss: 0.661754\t\n",
            "Validation (source) -> cls_loss: 0.043349\taccuracy: 98.8333%\n",
            "Validation (target) -> cls_loss: 0.790853\taccuracy: 76.0703%\n",
            "Epoch 42 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.010943\tcls_loss: 0.010062\tk_loss: 0.059535\tk: 0.243998\tlat_loss: 0.637003\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.054408\tcls_loss: 0.053599\tk_loss: 0.059599\tk: 0.244129\tlat_loss: 0.564775\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.022566\tcls_loss: 0.021907\tk_loss: 0.060288\tk: 0.245535\tlat_loss: 0.413644\t\n",
            "Validation (source) -> cls_loss: 0.054298\taccuracy: 98.4667%\n",
            "Validation (target) -> cls_loss: 0.812521\taccuracy: 73.7651%\n",
            "Epoch 43 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.087362\tcls_loss: 0.086639\tk_loss: 0.060313\tk: 0.245588\tlat_loss: 0.477599\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.004778\tcls_loss: 0.003952\tk_loss: 0.060384\tk: 0.245732\tlat_loss: 0.580606\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.006084\tcls_loss: 0.005278\tk_loss: 0.060449\tk: 0.245865\tlat_loss: 0.559624\t\n",
            "Validation (source) -> cls_loss: 0.047100\taccuracy: 98.7333%\n",
            "Validation (target) -> cls_loss: 0.840210\taccuracy: 74.0944%\n",
            "Epoch 44 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.010029\tcls_loss: 0.009221\tk_loss: 0.060449\tk: 0.245864\tlat_loss: 0.562212\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.006864\tcls_loss: 0.006067\tk_loss: 0.060435\tk: 0.245835\tlat_loss: 0.551145\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.006087\tcls_loss: 0.005305\tk_loss: 0.060501\tk: 0.245970\tlat_loss: 0.536475\t\n",
            "Validation (source) -> cls_loss: 0.050205\taccuracy: 98.6467%\n",
            "Validation (target) -> cls_loss: 0.815795\taccuracy: 70.8013%\n",
            "Epoch 45 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.049481\tcls_loss: 0.048718\tk_loss: 0.060536\tk: 0.246041\tlat_loss: 0.517220\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.017884\tcls_loss: 0.017019\tk_loss: 0.060595\tk: 0.246160\tlat_loss: 0.618860\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.049229\tcls_loss: 0.048520\tk_loss: 0.060693\tk: 0.246359\tlat_loss: 0.461870\t\n",
            "Validation (source) -> cls_loss: 0.050339\taccuracy: 98.7133%\n",
            "Validation (target) -> cls_loss: 0.630401\taccuracy: 78.5950%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 46 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.064113\tcls_loss: 0.063342\tk_loss: 0.060688\tk: 0.246349\tlat_loss: 0.523712\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.019060\tcls_loss: 0.018332\tk_loss: 0.060781\tk: 0.246538\tlat_loss: 0.480884\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.032873\tcls_loss: 0.032090\tk_loss: 0.060949\tk: 0.246879\tlat_loss: 0.536718\t\n",
            "Validation (source) -> cls_loss: 0.044770\taccuracy: 98.8067%\n",
            "Validation (target) -> cls_loss: 0.878083\taccuracy: 73.3260%\n",
            "Epoch 47 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.018972\tcls_loss: 0.018187\tk_loss: 0.060982\tk: 0.246946\tlat_loss: 0.538007\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.003358\tcls_loss: 0.002625\tk_loss: 0.061082\tk: 0.247147\tlat_loss: 0.485543\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.059488\tcls_loss: 0.058681\tk_loss: 0.061471\tk: 0.247934\tlat_loss: 0.559148\t\n",
            "Validation (source) -> cls_loss: 0.045106\taccuracy: 98.7200%\n",
            "Validation (target) -> cls_loss: 0.738357\taccuracy: 78.8694%\n",
            "Epoch 48 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.022351\tcls_loss: 0.021555\tk_loss: 0.061528\tk: 0.248049\tlat_loss: 0.547619\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.009809\tcls_loss: 0.009107\tk_loss: 0.061909\tk: 0.248816\tlat_loss: 0.453361\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.011150\tcls_loss: 0.010426\tk_loss: 0.061688\tk: 0.248370\tlat_loss: 0.475638\t\n",
            "Validation (source) -> cls_loss: 0.048224\taccuracy: 98.6600%\n",
            "Validation (target) -> cls_loss: 0.907723\taccuracy: 74.0944%\n",
            "Epoch 49 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.015339\tcls_loss: 0.014649\tk_loss: 0.061721\tk: 0.248437\tlat_loss: 0.441656\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.008266\tcls_loss: 0.007580\tk_loss: 0.063121\tk: 0.251238\tlat_loss: 0.434883\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.017088\tcls_loss: 0.016356\tk_loss: 0.064133\tk: 0.253245\tlat_loss: 0.479048\t\n",
            "Validation (source) -> cls_loss: 0.061314\taccuracy: 98.3533%\n",
            "Validation (target) -> cls_loss: 0.752755\taccuracy: 76.6191%\n",
            "Epoch 50 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.017770\tcls_loss: 0.017066\tk_loss: 0.064182\tk: 0.253341\tlat_loss: 0.450843\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.017123\tcls_loss: 0.016450\tk_loss: 0.064889\tk: 0.254732\tlat_loss: 0.418281\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.004257\tcls_loss: 0.003567\tk_loss: 0.065167\tk: 0.255279\tlat_loss: 0.434370\t\n",
            "Validation (source) -> cls_loss: 0.063527\taccuracy: 98.2733%\n",
            "Validation (target) -> cls_loss: 0.603813\taccuracy: 81.5587%\n",
            "Best model updated and saved at \"best_model.pt\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-d5399d3a46d0>:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  classifier.load_state_dict(torch.load(model_save_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test (source) -> cls_loss: 0.044152\taccuracy: 98.7800%\n",
            "Test (target) -> cls_loss: 0.763011\taccuracy: 78.1266%\n",
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "MyModel                                  [128, 10]                 --\n",
            "├─FeatureExtractor: 1-1                  [128, 64, 3, 3]           --\n",
            "│    └─ModuleList: 2-1                   --                        --\n",
            "│    │    └─Sequential: 3-1              [128, 16, 14, 14]         160\n",
            "│    │    └─Sequential: 3-2              [128, 32, 7, 7]           4,640\n",
            "│    │    └─Sequential: 3-3              [128, 64, 3, 3]           18,496\n",
            "├─DimensionReducer: 1-2                  [128, 576]                667,010\n",
            "├─ClassRegressor: 1-3                    [128, 10]                 --\n",
            "│    └─ModuleList: 2-2                   --                        --\n",
            "│    │    └─Sequential: 3-4              [128, 128]                73,856\n",
            "│    │    └─Sequential: 3-5              [128, 64]                 8,256\n",
            "│    └─Linear: 2-3                       [128, 10]                 650\n",
            "==========================================================================================\n",
            "Total params: 773,068\n",
            "Trainable params: 773,068\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 259.07\n",
            "==========================================================================================\n",
            "Input size (MB): 0.40\n",
            "Forward/backward pass size (MB): 22.69\n",
            "Params size (MB): 0.42\n",
            "Estimated Total Size (MB): 23.51\n",
            "==========================================================================================\n",
            "Epoch 1 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 2.306142\tcls_loss: 2.305428\tk_loss: 0.499678\tk: 0.706879\tlat_loss: 0.007050\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.975580\tcls_loss: 0.974865\tk_loss: 0.495954\tk: 0.704240\tlat_loss: 0.009918\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.290955\tcls_loss: 0.290229\tk_loss: 0.496832\tk: 0.704863\tlat_loss: 0.021814\t\n",
            "Validation (source) -> cls_loss: 0.390068\taccuracy: 88.0733%\n",
            "Validation (target) -> cls_loss: 0.962187\taccuracy: 69.2097%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 2 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.418199\tcls_loss: 0.417474\tk_loss: 0.496871\tk: 0.704891\tlat_loss: 0.019729\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.274267\tcls_loss: 0.273544\tk_loss: 0.497219\tk: 0.705137\tlat_loss: 0.018016\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.174191\tcls_loss: 0.173465\tk_loss: 0.498663\tk: 0.706161\tlat_loss: 0.019361\t\n",
            "Validation (source) -> cls_loss: 0.201231\taccuracy: 93.8467%\n",
            "Validation (target) -> cls_loss: 0.997254\taccuracy: 70.1427%\n",
            "Epoch 3 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.130993\tcls_loss: 0.130266\tk_loss: 0.498833\tk: 0.706281\tlat_loss: 0.020020\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.201236\tcls_loss: 0.200510\tk_loss: 0.499449\tk: 0.706717\tlat_loss: 0.019542\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.197592\tcls_loss: 0.196863\tk_loss: 0.500930\tk: 0.707764\tlat_loss: 0.021288\t\n",
            "Validation (source) -> cls_loss: 0.167207\taccuracy: 94.6600%\n",
            "Validation (target) -> cls_loss: 0.929205\taccuracy: 68.2217%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 4 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.210989\tcls_loss: 0.210259\tk_loss: 0.501029\tk: 0.707834\tlat_loss: 0.022364\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.119827\tcls_loss: 0.119097\tk_loss: 0.502344\tk: 0.708762\tlat_loss: 0.021321\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.082534\tcls_loss: 0.081804\tk_loss: 0.503373\tk: 0.709488\tlat_loss: 0.020969\t\n",
            "Validation (source) -> cls_loss: 0.120535\taccuracy: 96.2267%\n",
            "Validation (target) -> cls_loss: 1.046898\taccuracy: 66.2459%\n",
            "Epoch 5 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.119098\tcls_loss: 0.118367\tk_loss: 0.503228\tk: 0.709386\tlat_loss: 0.021509\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.148711\tcls_loss: 0.147983\tk_loss: 0.502702\tk: 0.709015\tlat_loss: 0.019197\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.016589\tcls_loss: 0.015857\tk_loss: 0.503396\tk: 0.709504\tlat_loss: 0.022184\t\n",
            "Validation (source) -> cls_loss: 0.101796\taccuracy: 96.8333%\n",
            "Validation (target) -> cls_loss: 1.167687\taccuracy: 67.2887%\n",
            "Epoch 6 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.069732\tcls_loss: 0.068999\tk_loss: 0.503291\tk: 0.709430\tlat_loss: 0.023456\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.096725\tcls_loss: 0.095993\tk_loss: 0.503108\tk: 0.709301\tlat_loss: 0.022362\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.073800\tcls_loss: 0.073069\tk_loss: 0.501390\tk: 0.708089\tlat_loss: 0.022913\t\n",
            "Validation (source) -> cls_loss: 0.089566\taccuracy: 97.3067%\n",
            "Validation (target) -> cls_loss: 1.238689\taccuracy: 67.9473%\n",
            "Epoch 7 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.052077\tcls_loss: 0.051347\tk_loss: 0.501053\tk: 0.707851\tlat_loss: 0.022232\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.081487\tcls_loss: 0.080759\tk_loss: 0.499794\tk: 0.706961\tlat_loss: 0.021190\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.099133\tcls_loss: 0.098405\tk_loss: 0.500705\tk: 0.707605\tlat_loss: 0.021081\t\n",
            "Validation (source) -> cls_loss: 0.079196\taccuracy: 97.5800%\n",
            "Validation (target) -> cls_loss: 0.852676\taccuracy: 74.0395%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 8 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.058246\tcls_loss: 0.057518\tk_loss: 0.500773\tk: 0.707653\tlat_loss: 0.020277\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.039373\tcls_loss: 0.038643\tk_loss: 0.501644\tk: 0.708268\tlat_loss: 0.021481\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.099989\tcls_loss: 0.099257\tk_loss: 0.501628\tk: 0.708257\tlat_loss: 0.023529\t\n",
            "Validation (source) -> cls_loss: 0.074583\taccuracy: 97.6400%\n",
            "Validation (target) -> cls_loss: 0.690339\taccuracy: 78.9243%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 9 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.052642\tcls_loss: 0.051908\tk_loss: 0.501656\tk: 0.708277\tlat_loss: 0.025460\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.090156\tcls_loss: 0.089422\tk_loss: 0.502973\tk: 0.709206\tlat_loss: 0.024357\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.087829\tcls_loss: 0.087094\tk_loss: 0.505163\tk: 0.710748\tlat_loss: 0.023796\t\n",
            "Validation (source) -> cls_loss: 0.077271\taccuracy: 97.7067%\n",
            "Validation (target) -> cls_loss: 0.895522\taccuracy: 74.2591%\n",
            "Epoch 10 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.038080\tcls_loss: 0.037349\tk_loss: 0.505138\tk: 0.710730\tlat_loss: 0.020890\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.019956\tcls_loss: 0.019223\tk_loss: 0.505174\tk: 0.710756\tlat_loss: 0.022159\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.043052\tcls_loss: 0.042321\tk_loss: 0.502815\tk: 0.709094\tlat_loss: 0.022298\t\n",
            "Validation (source) -> cls_loss: 0.065494\taccuracy: 97.8867%\n",
            "Validation (target) -> cls_loss: 0.800733\taccuracy: 75.9605%\n",
            "Epoch 11 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.056130\tcls_loss: 0.055401\tk_loss: 0.502797\tk: 0.709082\tlat_loss: 0.020634\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.053525\tcls_loss: 0.052792\tk_loss: 0.502285\tk: 0.708720\tlat_loss: 0.024640\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.026642\tcls_loss: 0.025911\tk_loss: 0.501458\tk: 0.708137\tlat_loss: 0.022610\t\n",
            "Validation (source) -> cls_loss: 0.070028\taccuracy: 97.8800%\n",
            "Validation (target) -> cls_loss: 1.064878\taccuracy: 69.1548%\n",
            "Epoch 12 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.050016\tcls_loss: 0.049286\tk_loss: 0.501386\tk: 0.708086\tlat_loss: 0.022023\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.062091\tcls_loss: 0.061359\tk_loss: 0.501841\tk: 0.708408\tlat_loss: 0.023593\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.037649\tcls_loss: 0.036915\tk_loss: 0.502314\tk: 0.708741\tlat_loss: 0.024991\t\n",
            "Validation (source) -> cls_loss: 0.062148\taccuracy: 98.0467%\n",
            "Validation (target) -> cls_loss: 1.153839\taccuracy: 70.4171%\n",
            "Epoch 13 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.039801\tcls_loss: 0.039066\tk_loss: 0.502396\tk: 0.708799\tlat_loss: 0.025489\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.108188\tcls_loss: 0.107453\tk_loss: 0.503197\tk: 0.709364\tlat_loss: 0.025628\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.067143\tcls_loss: 0.066408\tk_loss: 0.503987\tk: 0.709921\tlat_loss: 0.024989\t\n",
            "Validation (source) -> cls_loss: 0.074729\taccuracy: 97.5933%\n",
            "Validation (target) -> cls_loss: 1.419031\taccuracy: 65.2580%\n",
            "Epoch 14 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.074277\tcls_loss: 0.073543\tk_loss: 0.503865\tk: 0.709834\tlat_loss: 0.024467\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.035242\tcls_loss: 0.034508\tk_loss: 0.506913\tk: 0.711978\tlat_loss: 0.022748\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.019321\tcls_loss: 0.018583\tk_loss: 0.509540\tk: 0.713821\tlat_loss: 0.024067\t\n",
            "Validation (source) -> cls_loss: 0.062666\taccuracy: 97.9867%\n",
            "Validation (target) -> cls_loss: 0.990654\taccuracy: 71.2953%\n",
            "Epoch 15 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.056610\tcls_loss: 0.055871\tk_loss: 0.509675\tk: 0.713915\tlat_loss: 0.024579\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.023161\tcls_loss: 0.022423\tk_loss: 0.510555\tk: 0.714531\tlat_loss: 0.023436\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.028434\tcls_loss: 0.027697\tk_loss: 0.510102\tk: 0.714214\tlat_loss: 0.023063\t\n",
            "Validation (source) -> cls_loss: 0.063211\taccuracy: 97.9000%\n",
            "Validation (target) -> cls_loss: 1.000465\taccuracy: 73.2162%\n",
            "Epoch 16 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.012779\tcls_loss: 0.012042\tk_loss: 0.510122\tk: 0.714228\tlat_loss: 0.022752\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.041270\tcls_loss: 0.040533\tk_loss: 0.511223\tk: 0.714998\tlat_loss: 0.022453\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.038364\tcls_loss: 0.037627\tk_loss: 0.510904\tk: 0.714775\tlat_loss: 0.022677\t\n",
            "Validation (source) -> cls_loss: 0.053459\taccuracy: 98.4000%\n",
            "Validation (target) -> cls_loss: 0.767110\taccuracy: 78.5950%\n",
            "Epoch 17 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.024830\tcls_loss: 0.024090\tk_loss: 0.510793\tk: 0.714698\tlat_loss: 0.024841\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.043608\tcls_loss: 0.042872\tk_loss: 0.510133\tk: 0.714236\tlat_loss: 0.022742\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.027369\tcls_loss: 0.026632\tk_loss: 0.509516\tk: 0.713804\tlat_loss: 0.023708\t\n",
            "Validation (source) -> cls_loss: 0.070673\taccuracy: 97.8667%\n",
            "Validation (target) -> cls_loss: 0.760536\taccuracy: 72.7223%\n",
            "Epoch 18 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.033633\tcls_loss: 0.032896\tk_loss: 0.509473\tk: 0.713774\tlat_loss: 0.023402\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.085717\tcls_loss: 0.084981\tk_loss: 0.509043\tk: 0.713473\tlat_loss: 0.021920\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.069840\tcls_loss: 0.069100\tk_loss: 0.508928\tk: 0.713392\tlat_loss: 0.026110\t\n",
            "Validation (source) -> cls_loss: 0.054956\taccuracy: 98.3867%\n",
            "Validation (target) -> cls_loss: 0.917723\taccuracy: 77.9363%\n",
            "Epoch 19 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.046346\tcls_loss: 0.045608\tk_loss: 0.508965\tk: 0.713418\tlat_loss: 0.023842\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.084008\tcls_loss: 0.083274\tk_loss: 0.509214\tk: 0.713592\tlat_loss: 0.020254\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.026017\tcls_loss: 0.025279\tk_loss: 0.508634\tk: 0.713185\tlat_loss: 0.024512\t\n",
            "Validation (source) -> cls_loss: 0.052040\taccuracy: 98.4000%\n",
            "Validation (target) -> cls_loss: 1.085503\taccuracy: 74.0944%\n",
            "Epoch 20 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.061694\tcls_loss: 0.060958\tk_loss: 0.508823\tk: 0.713319\tlat_loss: 0.023145\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.044025\tcls_loss: 0.043291\tk_loss: 0.509089\tk: 0.713504\tlat_loss: 0.020839\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.062642\tcls_loss: 0.061907\tk_loss: 0.508735\tk: 0.713257\tlat_loss: 0.021567\t\n",
            "Validation (source) -> cls_loss: 0.063452\taccuracy: 98.0867%\n",
            "Validation (target) -> cls_loss: 0.993372\taccuracy: 72.2832%\n",
            "Epoch 21 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.052794\tcls_loss: 0.052059\tk_loss: 0.508745\tk: 0.713264\tlat_loss: 0.021836\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.063655\tcls_loss: 0.062918\tk_loss: 0.509531\tk: 0.713815\tlat_loss: 0.022806\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.016988\tcls_loss: 0.016252\tk_loss: 0.510461\tk: 0.714466\tlat_loss: 0.021741\t\n",
            "Validation (source) -> cls_loss: 0.053782\taccuracy: 98.3467%\n",
            "Validation (target) -> cls_loss: 0.750194\taccuracy: 76.8935%\n",
            "Epoch 22 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.027148\tcls_loss: 0.026413\tk_loss: 0.510497\tk: 0.714491\tlat_loss: 0.020247\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.040721\tcls_loss: 0.039981\tk_loss: 0.511277\tk: 0.715036\tlat_loss: 0.025727\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.026850\tcls_loss: 0.026112\tk_loss: 0.512620\tk: 0.715975\tlat_loss: 0.021601\t\n",
            "Validation (source) -> cls_loss: 0.058942\taccuracy: 98.1667%\n",
            "Validation (target) -> cls_loss: 0.586501\taccuracy: 81.2843%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 23 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.045868\tcls_loss: 0.045130\tk_loss: 0.512748\tk: 0.716064\tlat_loss: 0.022367\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.035797\tcls_loss: 0.035059\tk_loss: 0.514355\tk: 0.717185\tlat_loss: 0.021061\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.042932\tcls_loss: 0.042191\tk_loss: 0.515504\tk: 0.717986\tlat_loss: 0.023429\t\n",
            "Validation (source) -> cls_loss: 0.048747\taccuracy: 98.6067%\n",
            "Validation (target) -> cls_loss: 0.869394\taccuracy: 77.3326%\n",
            "Epoch 24 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.031828\tcls_loss: 0.031086\tk_loss: 0.515425\tk: 0.717931\tlat_loss: 0.024365\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.040523\tcls_loss: 0.039783\tk_loss: 0.516745\tk: 0.718850\tlat_loss: 0.021763\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.004170\tcls_loss: 0.003426\tk_loss: 0.520291\tk: 0.721312\tlat_loss: 0.022179\t\n",
            "Validation (source) -> cls_loss: 0.048691\taccuracy: 98.5067%\n",
            "Validation (target) -> cls_loss: 1.083654\taccuracy: 73.9297%\n",
            "Epoch 25 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.058635\tcls_loss: 0.057892\tk_loss: 0.520400\tk: 0.721388\tlat_loss: 0.022338\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.011776\tcls_loss: 0.011032\tk_loss: 0.520906\tk: 0.721738\tlat_loss: 0.022199\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.023768\tcls_loss: 0.023026\tk_loss: 0.519835\tk: 0.720995\tlat_loss: 0.020993\t\n",
            "Validation (source) -> cls_loss: 0.047910\taccuracy: 98.5133%\n",
            "Validation (target) -> cls_loss: 0.468374\taccuracy: 84.7969%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 26 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.018893\tcls_loss: 0.018151\tk_loss: 0.519843\tk: 0.721001\tlat_loss: 0.021000\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.009067\tcls_loss: 0.008326\tk_loss: 0.519009\tk: 0.720423\tlat_loss: 0.020298\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.048236\tcls_loss: 0.047494\tk_loss: 0.517261\tk: 0.719208\tlat_loss: 0.023164\t\n",
            "Validation (source) -> cls_loss: 0.046737\taccuracy: 98.6533%\n",
            "Validation (target) -> cls_loss: 0.795888\taccuracy: 79.3085%\n",
            "Epoch 27 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.002227\tcls_loss: 0.001485\tk_loss: 0.517138\tk: 0.719123\tlat_loss: 0.022802\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.050110\tcls_loss: 0.049367\tk_loss: 0.516755\tk: 0.718857\tlat_loss: 0.024830\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.037520\tcls_loss: 0.036778\tk_loss: 0.516228\tk: 0.718490\tlat_loss: 0.023066\t\n",
            "Validation (source) -> cls_loss: 0.047915\taccuracy: 98.6067%\n",
            "Validation (target) -> cls_loss: 0.616302\taccuracy: 79.9122%\n",
            "Epoch 28 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.005198\tcls_loss: 0.004456\tk_loss: 0.516656\tk: 0.718788\tlat_loss: 0.023898\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.030348\tcls_loss: 0.029606\tk_loss: 0.517945\tk: 0.719684\tlat_loss: 0.022695\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.055882\tcls_loss: 0.055137\tk_loss: 0.518124\tk: 0.719808\tlat_loss: 0.024638\t\n",
            "Validation (source) -> cls_loss: 0.045970\taccuracy: 98.6133%\n",
            "Validation (target) -> cls_loss: 0.984448\taccuracy: 75.7958%\n",
            "Epoch 29 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.028636\tcls_loss: 0.027895\tk_loss: 0.518014\tk: 0.719732\tlat_loss: 0.022056\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.032551\tcls_loss: 0.031811\tk_loss: 0.516981\tk: 0.719014\tlat_loss: 0.021319\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.008830\tcls_loss: 0.008087\tk_loss: 0.517640\tk: 0.719472\tlat_loss: 0.023779\t\n",
            "Validation (source) -> cls_loss: 0.052633\taccuracy: 98.3733%\n",
            "Validation (target) -> cls_loss: 0.579984\taccuracy: 82.8211%\n",
            "Epoch 30 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.029551\tcls_loss: 0.028808\tk_loss: 0.517783\tk: 0.719571\tlat_loss: 0.022966\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.023499\tcls_loss: 0.022753\tk_loss: 0.517658\tk: 0.719485\tlat_loss: 0.026461\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.091861\tcls_loss: 0.091117\tk_loss: 0.516735\tk: 0.718843\tlat_loss: 0.025491\t\n",
            "Validation (source) -> cls_loss: 0.047829\taccuracy: 98.4867%\n",
            "Validation (target) -> cls_loss: 0.593888\taccuracy: 82.4918%\n",
            "Epoch 31 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.095315\tcls_loss: 0.094570\tk_loss: 0.516609\tk: 0.718755\tlat_loss: 0.025759\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.040143\tcls_loss: 0.039397\tk_loss: 0.517943\tk: 0.719683\tlat_loss: 0.026208\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.014563\tcls_loss: 0.013819\tk_loss: 0.519202\tk: 0.720557\tlat_loss: 0.023867\t\n",
            "Validation (source) -> cls_loss: 0.048439\taccuracy: 98.5733%\n",
            "Validation (target) -> cls_loss: 0.936440\taccuracy: 75.2470%\n",
            "Epoch 32 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.014358\tcls_loss: 0.013613\tk_loss: 0.519192\tk: 0.720549\tlat_loss: 0.024344\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.006137\tcls_loss: 0.005392\tk_loss: 0.519212\tk: 0.720564\tlat_loss: 0.024198\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.033845\tcls_loss: 0.033098\tk_loss: 0.518740\tk: 0.720236\tlat_loss: 0.027128\t\n",
            "Validation (source) -> cls_loss: 0.053824\taccuracy: 98.4467%\n",
            "Validation (target) -> cls_loss: 0.865362\taccuracy: 77.7168%\n",
            "Epoch 33 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.012782\tcls_loss: 0.012036\tk_loss: 0.518736\tk: 0.720233\tlat_loss: 0.025453\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.007705\tcls_loss: 0.006958\tk_loss: 0.519865\tk: 0.721016\tlat_loss: 0.026148\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.020279\tcls_loss: 0.019533\tk_loss: 0.521849\tk: 0.722391\tlat_loss: 0.023568\t\n",
            "Validation (source) -> cls_loss: 0.045385\taccuracy: 98.6800%\n",
            "Validation (target) -> cls_loss: 0.961374\taccuracy: 72.5576%\n",
            "Epoch 34 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.018726\tcls_loss: 0.017980\tk_loss: 0.522010\tk: 0.722503\tlat_loss: 0.024025\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.021085\tcls_loss: 0.020336\tk_loss: 0.522035\tk: 0.722520\tlat_loss: 0.026846\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.003548\tcls_loss: 0.002801\tk_loss: 0.522506\tk: 0.722846\tlat_loss: 0.024639\t\n",
            "Validation (source) -> cls_loss: 0.040749\taccuracy: 98.7400%\n",
            "Validation (target) -> cls_loss: 0.686762\taccuracy: 78.7596%\n",
            "Epoch 35 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.002745\tcls_loss: 0.001997\tk_loss: 0.522538\tk: 0.722868\tlat_loss: 0.024290\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.005457\tcls_loss: 0.004707\tk_loss: 0.523185\tk: 0.723315\tlat_loss: 0.025994\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.002367\tcls_loss: 0.001621\tk_loss: 0.523496\tk: 0.723530\tlat_loss: 0.023230\t\n",
            "Validation (source) -> cls_loss: 0.047323\taccuracy: 98.7467%\n",
            "Validation (target) -> cls_loss: 0.757881\taccuracy: 80.0768%\n",
            "Epoch 36 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.004820\tcls_loss: 0.004072\tk_loss: 0.523471\tk: 0.723513\tlat_loss: 0.024506\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.002365\tcls_loss: 0.001618\tk_loss: 0.522923\tk: 0.723134\tlat_loss: 0.023667\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.022735\tcls_loss: 0.021988\tk_loss: 0.522687\tk: 0.722971\tlat_loss: 0.023674\t\n",
            "Validation (source) -> cls_loss: 0.043724\taccuracy: 98.6667%\n",
            "Validation (target) -> cls_loss: 0.736953\taccuracy: 80.3513%\n",
            "Epoch 37 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.020605\tcls_loss: 0.019857\tk_loss: 0.522660\tk: 0.722952\tlat_loss: 0.024271\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.050260\tcls_loss: 0.049513\tk_loss: 0.521357\tk: 0.722051\tlat_loss: 0.024373\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.004382\tcls_loss: 0.003637\tk_loss: 0.520768\tk: 0.721643\tlat_loss: 0.022861\t\n",
            "Validation (source) -> cls_loss: 0.046246\taccuracy: 98.6800%\n",
            "Validation (target) -> cls_loss: 0.605266\taccuracy: 83.3150%\n",
            "Epoch 38 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.018660\tcls_loss: 0.017915\tk_loss: 0.520758\tk: 0.721636\tlat_loss: 0.024330\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.014898\tcls_loss: 0.014150\tk_loss: 0.520193\tk: 0.721244\tlat_loss: 0.026184\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.052614\tcls_loss: 0.051868\tk_loss: 0.521711\tk: 0.722295\tlat_loss: 0.023125\t\n",
            "Validation (source) -> cls_loss: 0.046102\taccuracy: 98.7800%\n",
            "Validation (target) -> cls_loss: 0.712652\taccuracy: 80.1866%\n",
            "Epoch 39 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.017749\tcls_loss: 0.017003\tk_loss: 0.521736\tk: 0.722313\tlat_loss: 0.023828\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.014159\tcls_loss: 0.013416\tk_loss: 0.521990\tk: 0.722489\tlat_loss: 0.021027\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.004173\tcls_loss: 0.003426\tk_loss: 0.522300\tk: 0.722703\tlat_loss: 0.023633\t\n",
            "Validation (source) -> cls_loss: 0.041261\taccuracy: 98.7933%\n",
            "Validation (target) -> cls_loss: 0.825352\taccuracy: 78.1559%\n",
            "Epoch 40 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.042025\tcls_loss: 0.041279\tk_loss: 0.522330\tk: 0.722724\tlat_loss: 0.022441\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.031101\tcls_loss: 0.030353\tk_loss: 0.522436\tk: 0.722797\tlat_loss: 0.024849\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.005920\tcls_loss: 0.005172\tk_loss: 0.523228\tk: 0.723345\tlat_loss: 0.025060\t\n",
            "Validation (source) -> cls_loss: 0.046560\taccuracy: 98.7467%\n",
            "Validation (target) -> cls_loss: 0.966718\taccuracy: 77.2777%\n",
            "Epoch 41 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.001871\tcls_loss: 0.001120\tk_loss: 0.523238\tk: 0.723352\tlat_loss: 0.027707\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.018666\tcls_loss: 0.017917\tk_loss: 0.523103\tk: 0.723259\tlat_loss: 0.025801\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.010537\tcls_loss: 0.009792\tk_loss: 0.523058\tk: 0.723228\tlat_loss: 0.021080\t\n",
            "Validation (source) -> cls_loss: 0.041544\taccuracy: 98.7133%\n",
            "Validation (target) -> cls_loss: 0.697466\taccuracy: 78.5401%\n",
            "Epoch 42 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.002926\tcls_loss: 0.002182\tk_loss: 0.523051\tk: 0.723222\tlat_loss: 0.020714\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.003730\tcls_loss: 0.002983\tk_loss: 0.522223\tk: 0.722650\tlat_loss: 0.024372\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.002956\tcls_loss: 0.002210\tk_loss: 0.521275\tk: 0.721993\tlat_loss: 0.023929\t\n",
            "Validation (source) -> cls_loss: 0.037226\taccuracy: 98.8867%\n",
            "Validation (target) -> cls_loss: 0.887724\taccuracy: 76.8386%\n",
            "Epoch 43 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.006959\tcls_loss: 0.006213\tk_loss: 0.521207\tk: 0.721947\tlat_loss: 0.023936\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.008942\tcls_loss: 0.008195\tk_loss: 0.521423\tk: 0.722096\tlat_loss: 0.024621\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.003840\tcls_loss: 0.003093\tk_loss: 0.522882\tk: 0.723106\tlat_loss: 0.024524\t\n",
            "Validation (source) -> cls_loss: 0.045622\taccuracy: 98.6667%\n",
            "Validation (target) -> cls_loss: 0.911028\taccuracy: 75.5214%\n",
            "Epoch 44 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.020077\tcls_loss: 0.019329\tk_loss: 0.522984\tk: 0.723176\tlat_loss: 0.024023\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.002898\tcls_loss: 0.002148\tk_loss: 0.523964\tk: 0.723853\tlat_loss: 0.026682\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.008500\tcls_loss: 0.007750\tk_loss: 0.525177\tk: 0.724691\tlat_loss: 0.025309\t\n",
            "Validation (source) -> cls_loss: 0.051495\taccuracy: 98.4533%\n",
            "Validation (target) -> cls_loss: 0.509212\taccuracy: 84.8518%\n",
            "Epoch 45 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.102102\tcls_loss: 0.101353\tk_loss: 0.525169\tk: 0.724685\tlat_loss: 0.023960\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.065160\tcls_loss: 0.064412\tk_loss: 0.527571\tk: 0.726341\tlat_loss: 0.021390\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.005872\tcls_loss: 0.005125\tk_loss: 0.529431\tk: 0.727620\tlat_loss: 0.019986\t\n",
            "Validation (source) -> cls_loss: 0.046684\taccuracy: 98.6400%\n",
            "Validation (target) -> cls_loss: 0.536081\taccuracy: 83.9737%\n",
            "Epoch 46 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.021645\tcls_loss: 0.020896\tk_loss: 0.529645\tk: 0.727767\tlat_loss: 0.021214\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.009568\tcls_loss: 0.008820\tk_loss: 0.530995\tk: 0.728694\tlat_loss: 0.019195\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.013659\tcls_loss: 0.012912\tk_loss: 0.530811\tk: 0.728568\tlat_loss: 0.018055\t\n",
            "Validation (source) -> cls_loss: 0.044496\taccuracy: 98.5067%\n",
            "Validation (target) -> cls_loss: 0.737483\taccuracy: 78.0461%\n",
            "Epoch 47 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.033060\tcls_loss: 0.032314\tk_loss: 0.530688\tk: 0.728483\tlat_loss: 0.017249\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.013383\tcls_loss: 0.012634\tk_loss: 0.529936\tk: 0.727967\tlat_loss: 0.021689\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.004551\tcls_loss: 0.003802\tk_loss: 0.530121\tk: 0.728094\tlat_loss: 0.020711\t\n",
            "Validation (source) -> cls_loss: 0.043553\taccuracy: 98.7200%\n",
            "Validation (target) -> cls_loss: 0.735903\taccuracy: 81.2843%\n",
            "Epoch 48 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.038898\tcls_loss: 0.038148\tk_loss: 0.530211\tk: 0.728156\tlat_loss: 0.021702\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.029972\tcls_loss: 0.029222\tk_loss: 0.530560\tk: 0.728396\tlat_loss: 0.022288\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.018557\tcls_loss: 0.017805\tk_loss: 0.530814\tk: 0.728570\tlat_loss: 0.023308\t\n",
            "Validation (source) -> cls_loss: 0.039524\taccuracy: 98.8933%\n",
            "Validation (target) -> cls_loss: 0.711010\taccuracy: 81.8332%\n",
            "Epoch 49 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.004092\tcls_loss: 0.003339\tk_loss: 0.530962\tk: 0.728671\tlat_loss: 0.025091\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.004738\tcls_loss: 0.003988\tk_loss: 0.531888\tk: 0.729306\tlat_loss: 0.020642\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.002782\tcls_loss: 0.002032\tk_loss: 0.533032\tk: 0.730091\tlat_loss: 0.020446\t\n",
            "Validation (source) -> cls_loss: 0.042188\taccuracy: 98.8067%\n",
            "Validation (target) -> cls_loss: 0.695507\taccuracy: 80.0768%\n",
            "Epoch 50 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.015851\tcls_loss: 0.015099\tk_loss: 0.533166\tk: 0.730182\tlat_loss: 0.021717\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.002404\tcls_loss: 0.001653\tk_loss: 0.533969\tk: 0.730732\tlat_loss: 0.020584\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.002429\tcls_loss: 0.001678\tk_loss: 0.534975\tk: 0.731420\tlat_loss: 0.019575\t\n",
            "Validation (source) -> cls_loss: 0.042088\taccuracy: 98.7400%\n",
            "Validation (target) -> cls_loss: 0.682728\taccuracy: 79.8573%\n",
            "Test (source) -> cls_loss: 0.038836\taccuracy: 98.8100%\n",
            "Test (target) -> cls_loss: 0.605420\taccuracy: 81.6642%\n",
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "MyModel                                  [128, 10]                 --\n",
            "├─FeatureExtractor: 1-1                  [128, 64, 3, 3]           --\n",
            "│    └─ModuleList: 2-1                   --                        --\n",
            "│    │    └─Sequential: 3-1              [128, 16, 14, 14]         160\n",
            "│    │    └─Sequential: 3-2              [128, 32, 7, 7]           4,640\n",
            "│    │    └─Sequential: 3-3              [128, 64, 3, 3]           18,496\n",
            "├─DimensionReducer: 1-2                  [128, 576]                667,010\n",
            "├─ClassRegressor: 1-3                    [128, 10]                 --\n",
            "│    └─ModuleList: 2-2                   --                        --\n",
            "│    │    └─Sequential: 3-4              [128, 128]                73,856\n",
            "│    │    └─Sequential: 3-5              [128, 64]                 8,256\n",
            "│    └─Linear: 2-3                       [128, 10]                 650\n",
            "==========================================================================================\n",
            "Total params: 773,068\n",
            "Trainable params: 773,068\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 259.07\n",
            "==========================================================================================\n",
            "Input size (MB): 0.40\n",
            "Forward/backward pass size (MB): 22.69\n",
            "Params size (MB): 0.42\n",
            "Estimated Total Size (MB): 23.51\n",
            "==========================================================================================\n",
            "Epoch 1 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 2.306029\tcls_loss: 2.305329\tk_loss: 0.486435\tk: 0.697449\tlat_loss: 0.002845\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 1.102932\tcls_loss: 1.102232\tk_loss: 0.484257\tk: 0.695885\tlat_loss: 0.004314\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.504003\tcls_loss: 0.503283\tk_loss: 0.486424\tk: 0.697441\tlat_loss: 0.022239\t\n",
            "Validation (source) -> cls_loss: 0.474258\taccuracy: 85.2600%\n",
            "Validation (target) -> cls_loss: 0.908557\taccuracy: 70.5818%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 2 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.502362\tcls_loss: 0.501642\tk_loss: 0.486485\tk: 0.697485\tlat_loss: 0.022417\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.261061\tcls_loss: 0.260340\tk_loss: 0.488130\tk: 0.698663\tlat_loss: 0.021888\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.220482\tcls_loss: 0.219762\tk_loss: 0.489293\tk: 0.699495\tlat_loss: 0.020961\t\n",
            "Validation (source) -> cls_loss: 0.189225\taccuracy: 94.4333%\n",
            "Validation (target) -> cls_loss: 1.040428\taccuracy: 68.6059%\n",
            "Epoch 3 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.100140\tcls_loss: 0.099421\tk_loss: 0.489408\tk: 0.699577\tlat_loss: 0.020137\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.258480\tcls_loss: 0.257760\tk_loss: 0.490365\tk: 0.700261\tlat_loss: 0.019286\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.124151\tcls_loss: 0.123430\tk_loss: 0.490777\tk: 0.700555\tlat_loss: 0.020347\t\n",
            "Validation (source) -> cls_loss: 0.141781\taccuracy: 95.4867%\n",
            "Validation (target) -> cls_loss: 0.789279\taccuracy: 74.8079%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 4 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.136953\tcls_loss: 0.136232\tk_loss: 0.490884\tk: 0.700631\tlat_loss: 0.020106\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.110327\tcls_loss: 0.109608\tk_loss: 0.492008\tk: 0.701433\tlat_loss: 0.017955\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.090128\tcls_loss: 0.089407\tk_loss: 0.491936\tk: 0.701381\tlat_loss: 0.019733\t\n",
            "Validation (source) -> cls_loss: 0.104227\taccuracy: 96.8933%\n",
            "Validation (target) -> cls_loss: 0.846076\taccuracy: 75.5214%\n",
            "Epoch 5 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.035597\tcls_loss: 0.034875\tk_loss: 0.492002\tk: 0.701429\tlat_loss: 0.020791\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.073935\tcls_loss: 0.073213\tk_loss: 0.494844\tk: 0.703451\tlat_loss: 0.018489\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.062598\tcls_loss: 0.061873\tk_loss: 0.495619\tk: 0.704002\tlat_loss: 0.020790\t\n",
            "Validation (source) -> cls_loss: 0.092673\taccuracy: 97.0267%\n",
            "Validation (target) -> cls_loss: 0.956594\taccuracy: 72.5027%\n",
            "Epoch 6 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.067322\tcls_loss: 0.066597\tk_loss: 0.495678\tk: 0.704044\tlat_loss: 0.021147\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.093004\tcls_loss: 0.092279\tk_loss: 0.495376\tk: 0.703829\tlat_loss: 0.021451\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.135959\tcls_loss: 0.135232\tk_loss: 0.497848\tk: 0.705583\tlat_loss: 0.021177\t\n",
            "Validation (source) -> cls_loss: 0.104204\taccuracy: 96.6867%\n",
            "Validation (target) -> cls_loss: 0.716658\taccuracy: 79.3085%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 7 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.136961\tcls_loss: 0.136235\tk_loss: 0.498129\tk: 0.705783\tlat_loss: 0.020553\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.163889\tcls_loss: 0.163166\tk_loss: 0.498344\tk: 0.705935\tlat_loss: 0.016788\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.124854\tcls_loss: 0.124131\tk_loss: 0.498318\tk: 0.705916\tlat_loss: 0.016336\t\n",
            "Validation (source) -> cls_loss: 0.078859\taccuracy: 97.5800%\n",
            "Validation (target) -> cls_loss: 0.774508\taccuracy: 76.6191%\n",
            "Epoch 8 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.083122\tcls_loss: 0.082398\tk_loss: 0.498357\tk: 0.705944\tlat_loss: 0.017784\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.040590\tcls_loss: 0.039866\tk_loss: 0.499150\tk: 0.706506\tlat_loss: 0.017217\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.058964\tcls_loss: 0.058239\tk_loss: 0.499303\tk: 0.706613\tlat_loss: 0.018002\t\n",
            "Validation (source) -> cls_loss: 0.072565\taccuracy: 97.7067%\n",
            "Validation (target) -> cls_loss: 0.598454\taccuracy: 82.3271%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 9 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.032795\tcls_loss: 0.032070\tk_loss: 0.499270\tk: 0.706590\tlat_loss: 0.018554\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.031524\tcls_loss: 0.030796\tk_loss: 0.499107\tk: 0.706475\tlat_loss: 0.021016\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.050353\tcls_loss: 0.049628\tk_loss: 0.498344\tk: 0.705935\tlat_loss: 0.018776\t\n",
            "Validation (source) -> cls_loss: 0.065974\taccuracy: 97.8933%\n",
            "Validation (target) -> cls_loss: 0.689170\taccuracy: 78.6498%\n",
            "Epoch 10 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.025698\tcls_loss: 0.024971\tk_loss: 0.498283\tk: 0.705891\tlat_loss: 0.020736\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.054804\tcls_loss: 0.054079\tk_loss: 0.497180\tk: 0.705110\tlat_loss: 0.020000\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.054192\tcls_loss: 0.053466\tk_loss: 0.497910\tk: 0.705628\tlat_loss: 0.020177\t\n",
            "Validation (source) -> cls_loss: 0.072236\taccuracy: 97.6533%\n",
            "Validation (target) -> cls_loss: 0.969284\taccuracy: 69.1548%\n",
            "Epoch 11 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.011893\tcls_loss: 0.011167\tk_loss: 0.498036\tk: 0.705717\tlat_loss: 0.019386\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.061120\tcls_loss: 0.060396\tk_loss: 0.500281\tk: 0.707305\tlat_loss: 0.016462\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.046998\tcls_loss: 0.046270\tk_loss: 0.501659\tk: 0.708279\tlat_loss: 0.019993\t\n",
            "Validation (source) -> cls_loss: 0.066377\taccuracy: 97.9533%\n",
            "Validation (target) -> cls_loss: 0.860322\taccuracy: 76.4544%\n",
            "Epoch 12 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.016603\tcls_loss: 0.015875\tk_loss: 0.501986\tk: 0.708510\tlat_loss: 0.019966\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.041952\tcls_loss: 0.041222\tk_loss: 0.505724\tk: 0.711143\tlat_loss: 0.018800\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.068609\tcls_loss: 0.067878\tk_loss: 0.507266\tk: 0.712226\tlat_loss: 0.018716\t\n",
            "Validation (source) -> cls_loss: 0.062071\taccuracy: 98.0667%\n",
            "Validation (target) -> cls_loss: 0.775623\taccuracy: 78.4303%\n",
            "Epoch 13 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.054552\tcls_loss: 0.053821\tk_loss: 0.507600\tk: 0.712461\tlat_loss: 0.019167\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.016221\tcls_loss: 0.015489\tk_loss: 0.508956\tk: 0.713412\tlat_loss: 0.019048\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.033344\tcls_loss: 0.032612\tk_loss: 0.509613\tk: 0.713872\tlat_loss: 0.017223\t\n",
            "Validation (source) -> cls_loss: 0.063236\taccuracy: 98.1467%\n",
            "Validation (target) -> cls_loss: 0.678513\taccuracy: 80.4610%\n",
            "Epoch 14 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.074980\tcls_loss: 0.074249\tk_loss: 0.509712\tk: 0.713941\tlat_loss: 0.016832\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.018718\tcls_loss: 0.017983\tk_loss: 0.509336\tk: 0.713678\tlat_loss: 0.021712\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.008926\tcls_loss: 0.008194\tk_loss: 0.508722\tk: 0.713248\tlat_loss: 0.019403\t\n",
            "Validation (source) -> cls_loss: 0.057493\taccuracy: 98.1867%\n",
            "Validation (target) -> cls_loss: 0.929175\taccuracy: 73.4358%\n",
            "Epoch 15 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.020535\tcls_loss: 0.019802\tk_loss: 0.508550\tk: 0.713127\tlat_loss: 0.020231\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.034865\tcls_loss: 0.034132\tk_loss: 0.508081\tk: 0.712798\tlat_loss: 0.020795\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.028680\tcls_loss: 0.027950\tk_loss: 0.509690\tk: 0.713926\tlat_loss: 0.016746\t\n",
            "Validation (source) -> cls_loss: 0.060145\taccuracy: 98.1000%\n",
            "Validation (target) -> cls_loss: 0.639465\taccuracy: 80.2964%\n",
            "Epoch 16 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.035705\tcls_loss: 0.034973\tk_loss: 0.509924\tk: 0.714090\tlat_loss: 0.017935\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.065683\tcls_loss: 0.064947\tk_loss: 0.511247\tk: 0.715016\tlat_loss: 0.021400\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.011951\tcls_loss: 0.011216\tk_loss: 0.511904\tk: 0.715474\tlat_loss: 0.019420\t\n",
            "Validation (source) -> cls_loss: 0.056897\taccuracy: 98.2800%\n",
            "Validation (target) -> cls_loss: 1.080253\taccuracy: 74.1493%\n",
            "Epoch 17 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.011903\tcls_loss: 0.011167\tk_loss: 0.511922\tk: 0.715487\tlat_loss: 0.020527\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.026811\tcls_loss: 0.026076\tk_loss: 0.512470\tk: 0.715870\tlat_loss: 0.018732\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.066114\tcls_loss: 0.065378\tk_loss: 0.514630\tk: 0.717377\tlat_loss: 0.018148\t\n",
            "Validation (source) -> cls_loss: 0.055571\taccuracy: 98.2800%\n",
            "Validation (target) -> cls_loss: 0.843251\taccuracy: 76.7289%\n",
            "Epoch 18 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.013481\tcls_loss: 0.012745\tk_loss: 0.514882\tk: 0.717553\tlat_loss: 0.018433\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.106586\tcls_loss: 0.105846\tk_loss: 0.516398\tk: 0.718608\tlat_loss: 0.020948\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.031571\tcls_loss: 0.030831\tk_loss: 0.518687\tk: 0.720200\tlat_loss: 0.020504\t\n",
            "Validation (source) -> cls_loss: 0.052428\taccuracy: 98.2867%\n",
            "Validation (target) -> cls_loss: 0.908221\taccuracy: 73.9846%\n",
            "Epoch 19 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.044507\tcls_loss: 0.043765\tk_loss: 0.518858\tk: 0.720318\tlat_loss: 0.021389\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.013033\tcls_loss: 0.012293\tk_loss: 0.520065\tk: 0.721155\tlat_loss: 0.018992\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.059037\tcls_loss: 0.058298\tk_loss: 0.520135\tk: 0.721204\tlat_loss: 0.017552\t\n",
            "Validation (source) -> cls_loss: 0.045898\taccuracy: 98.6467%\n",
            "Validation (target) -> cls_loss: 0.713537\taccuracy: 78.8694%\n",
            "Epoch 20 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.051329\tcls_loss: 0.050590\tk_loss: 0.520230\tk: 0.721270\tlat_loss: 0.017622\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.006935\tcls_loss: 0.006193\tk_loss: 0.520511\tk: 0.721465\tlat_loss: 0.020264\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.027535\tcls_loss: 0.026794\tk_loss: 0.521165\tk: 0.721918\tlat_loss: 0.018678\t\n",
            "Validation (source) -> cls_loss: 0.048630\taccuracy: 98.6000%\n",
            "Validation (target) -> cls_loss: 0.657737\taccuracy: 81.8332%\n",
            "Epoch 21 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.009412\tcls_loss: 0.008671\tk_loss: 0.521160\tk: 0.721914\tlat_loss: 0.018979\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.045446\tcls_loss: 0.044702\tk_loss: 0.520757\tk: 0.721635\tlat_loss: 0.022317\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.048736\tcls_loss: 0.047993\tk_loss: 0.521882\tk: 0.722414\tlat_loss: 0.021323\t\n",
            "Validation (source) -> cls_loss: 0.066689\taccuracy: 97.8800%\n",
            "Validation (target) -> cls_loss: 0.759352\taccuracy: 74.6432%\n",
            "Epoch 22 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.035364\tcls_loss: 0.034619\tk_loss: 0.522069\tk: 0.722543\tlat_loss: 0.022247\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.019177\tcls_loss: 0.018429\tk_loss: 0.523912\tk: 0.723818\tlat_loss: 0.023752\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.019904\tcls_loss: 0.019160\tk_loss: 0.525604\tk: 0.724986\tlat_loss: 0.019619\t\n",
            "Validation (source) -> cls_loss: 0.044938\taccuracy: 98.7133%\n",
            "Validation (target) -> cls_loss: 0.739601\taccuracy: 77.7168%\n",
            "Epoch 23 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.022548\tcls_loss: 0.021802\tk_loss: 0.525783\tk: 0.725109\tlat_loss: 0.020410\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.045073\tcls_loss: 0.044323\tk_loss: 0.529525\tk: 0.727685\tlat_loss: 0.022957\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.055852\tcls_loss: 0.055103\tk_loss: 0.531778\tk: 0.729231\tlat_loss: 0.020030\t\n",
            "Validation (source) -> cls_loss: 0.051964\taccuracy: 98.4733%\n",
            "Validation (target) -> cls_loss: 0.516501\taccuracy: 84.5225%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 24 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.039874\tcls_loss: 0.039123\tk_loss: 0.531993\tk: 0.729378\tlat_loss: 0.020790\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.035778\tcls_loss: 0.035023\tk_loss: 0.533252\tk: 0.730241\tlat_loss: 0.024819\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.031853\tcls_loss: 0.031100\tk_loss: 0.533395\tk: 0.730339\tlat_loss: 0.022901\t\n",
            "Validation (source) -> cls_loss: 0.065375\taccuracy: 98.1267%\n",
            "Validation (target) -> cls_loss: 0.538077\taccuracy: 83.5895%\n",
            "Epoch 25 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.063695\tcls_loss: 0.062941\tk_loss: 0.533400\tk: 0.730342\tlat_loss: 0.023493\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.071751\tcls_loss: 0.070996\tk_loss: 0.532875\tk: 0.729983\tlat_loss: 0.024809\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.065635\tcls_loss: 0.064881\tk_loss: 0.532762\tk: 0.729906\tlat_loss: 0.024693\t\n",
            "Validation (source) -> cls_loss: 0.058322\taccuracy: 98.3733%\n",
            "Validation (target) -> cls_loss: 0.640982\taccuracy: 81.8332%\n",
            "Epoch 26 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.006095\tcls_loss: 0.005340\tk_loss: 0.532817\tk: 0.729943\tlat_loss: 0.025116\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.028235\tcls_loss: 0.027482\tk_loss: 0.533473\tk: 0.730392\tlat_loss: 0.023180\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.027477\tcls_loss: 0.026722\tk_loss: 0.535626\tk: 0.731865\tlat_loss: 0.023381\t\n",
            "Validation (source) -> cls_loss: 0.049919\taccuracy: 98.5600%\n",
            "Validation (target) -> cls_loss: 0.645136\taccuracy: 80.5159%\n",
            "Epoch 27 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.026893\tcls_loss: 0.026137\tk_loss: 0.535826\tk: 0.732001\tlat_loss: 0.023878\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.082531\tcls_loss: 0.081775\tk_loss: 0.536743\tk: 0.732628\tlat_loss: 0.023170\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.062395\tcls_loss: 0.061638\tk_loss: 0.536694\tk: 0.732594\tlat_loss: 0.024657\t\n",
            "Validation (source) -> cls_loss: 0.059671\taccuracy: 98.3667%\n",
            "Validation (target) -> cls_loss: 0.732355\taccuracy: 78.1559%\n",
            "Epoch 28 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.051221\tcls_loss: 0.050465\tk_loss: 0.536998\tk: 0.732802\tlat_loss: 0.023034\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.002098\tcls_loss: 0.001339\tk_loss: 0.542765\tk: 0.736726\tlat_loss: 0.022912\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.013050\tcls_loss: 0.012288\tk_loss: 0.546136\tk: 0.739010\tlat_loss: 0.022657\t\n",
            "Validation (source) -> cls_loss: 0.051370\taccuracy: 98.4800%\n",
            "Validation (target) -> cls_loss: 0.895656\taccuracy: 76.2898%\n",
            "Epoch 29 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.012643\tcls_loss: 0.011880\tk_loss: 0.546230\tk: 0.739074\tlat_loss: 0.024052\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.002650\tcls_loss: 0.001888\tk_loss: 0.546640\tk: 0.739351\tlat_loss: 0.022659\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.045491\tcls_loss: 0.044733\tk_loss: 0.546963\tk: 0.739570\tlat_loss: 0.018338\t\n",
            "Validation (source) -> cls_loss: 0.053397\taccuracy: 98.4333%\n",
            "Validation (target) -> cls_loss: 0.822818\taccuracy: 76.6740%\n",
            "Epoch 30 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.102242\tcls_loss: 0.101481\tk_loss: 0.546973\tk: 0.739576\tlat_loss: 0.021021\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.011670\tcls_loss: 0.010909\tk_loss: 0.547895\tk: 0.740199\tlat_loss: 0.020823\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.073987\tcls_loss: 0.073227\tk_loss: 0.549258\tk: 0.741119\tlat_loss: 0.018831\t\n",
            "Validation (source) -> cls_loss: 0.052054\taccuracy: 98.5267%\n",
            "Validation (target) -> cls_loss: 0.750157\taccuracy: 77.8266%\n",
            "Epoch 31 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.019112\tcls_loss: 0.018353\tk_loss: 0.549169\tk: 0.741060\tlat_loss: 0.017696\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.040193\tcls_loss: 0.039434\tk_loss: 0.547464\tk: 0.739908\tlat_loss: 0.018632\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.005449\tcls_loss: 0.004688\tk_loss: 0.547957\tk: 0.740241\tlat_loss: 0.020353\t\n",
            "Validation (source) -> cls_loss: 0.047013\taccuracy: 98.6067%\n",
            "Validation (target) -> cls_loss: 0.848581\taccuracy: 75.7958%\n",
            "Epoch 32 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.021691\tcls_loss: 0.020931\tk_loss: 0.548111\tk: 0.740345\tlat_loss: 0.019485\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.040864\tcls_loss: 0.040104\tk_loss: 0.548713\tk: 0.740752\tlat_loss: 0.019704\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.013855\tcls_loss: 0.013096\tk_loss: 0.547503\tk: 0.739934\tlat_loss: 0.019340\t\n",
            "Validation (source) -> cls_loss: 0.048895\taccuracy: 98.4867%\n",
            "Validation (target) -> cls_loss: 0.774860\taccuracy: 78.3754%\n",
            "Epoch 33 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.012111\tcls_loss: 0.011353\tk_loss: 0.547314\tk: 0.739807\tlat_loss: 0.018270\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.004755\tcls_loss: 0.003998\tk_loss: 0.547235\tk: 0.739753\tlat_loss: 0.017276\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.026880\tcls_loss: 0.026119\tk_loss: 0.548701\tk: 0.740744\tlat_loss: 0.020535\t\n",
            "Validation (source) -> cls_loss: 0.043267\taccuracy: 98.7733%\n",
            "Validation (target) -> cls_loss: 0.784091\taccuracy: 78.4852%\n",
            "Epoch 34 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.011134\tcls_loss: 0.010373\tk_loss: 0.548813\tk: 0.740819\tlat_loss: 0.019651\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.009217\tcls_loss: 0.008457\tk_loss: 0.548736\tk: 0.740767\tlat_loss: 0.019306\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.035577\tcls_loss: 0.034814\tk_loss: 0.548542\tk: 0.740636\tlat_loss: 0.022425\t\n",
            "Validation (source) -> cls_loss: 0.046300\taccuracy: 98.6733%\n",
            "Validation (target) -> cls_loss: 1.037541\taccuracy: 73.9297%\n",
            "Epoch 35 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.016632\tcls_loss: 0.015868\tk_loss: 0.548619\tk: 0.740688\tlat_loss: 0.023523\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.014181\tcls_loss: 0.013420\tk_loss: 0.548898\tk: 0.740876\tlat_loss: 0.020086\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.012573\tcls_loss: 0.011812\tk_loss: 0.548444\tk: 0.740570\tlat_loss: 0.020368\t\n",
            "Validation (source) -> cls_loss: 0.044579\taccuracy: 98.7400%\n",
            "Validation (target) -> cls_loss: 0.592980\taccuracy: 81.9978%\n",
            "Epoch 36 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.018656\tcls_loss: 0.017893\tk_loss: 0.548577\tk: 0.740660\tlat_loss: 0.021650\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.045562\tcls_loss: 0.044800\tk_loss: 0.548500\tk: 0.740608\tlat_loss: 0.021375\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.004045\tcls_loss: 0.003286\tk_loss: 0.548264\tk: 0.740449\tlat_loss: 0.018832\t\n",
            "Validation (source) -> cls_loss: 0.045315\taccuracy: 98.7467%\n",
            "Validation (target) -> cls_loss: 0.735939\taccuracy: 76.7289%\n",
            "Epoch 37 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.014900\tcls_loss: 0.014139\tk_loss: 0.548227\tk: 0.740424\tlat_loss: 0.020875\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.024763\tcls_loss: 0.024003\tk_loss: 0.547193\tk: 0.739725\tlat_loss: 0.019973\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.023673\tcls_loss: 0.022915\tk_loss: 0.545745\tk: 0.738746\tlat_loss: 0.019155\t\n",
            "Validation (source) -> cls_loss: 0.046657\taccuracy: 98.5800%\n",
            "Validation (target) -> cls_loss: 0.565192\taccuracy: 82.9857%\n",
            "Epoch 38 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.078313\tcls_loss: 0.077556\tk_loss: 0.545780\tk: 0.738769\tlat_loss: 0.018018\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.016435\tcls_loss: 0.015675\tk_loss: 0.547056\tk: 0.739632\tlat_loss: 0.020091\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.034248\tcls_loss: 0.033485\tk_loss: 0.551402\tk: 0.742565\tlat_loss: 0.020093\t\n",
            "Validation (source) -> cls_loss: 0.049965\taccuracy: 98.6667%\n",
            "Validation (target) -> cls_loss: 0.698130\taccuracy: 77.3326%\n",
            "Epoch 39 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.002220\tcls_loss: 0.001458\tk_loss: 0.551784\tk: 0.742822\tlat_loss: 0.019562\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.056307\tcls_loss: 0.055548\tk_loss: 0.552445\tk: 0.743266\tlat_loss: 0.016086\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.069460\tcls_loss: 0.068697\tk_loss: 0.554721\tk: 0.744796\tlat_loss: 0.018251\t\n",
            "Validation (source) -> cls_loss: 0.049445\taccuracy: 98.4800%\n",
            "Validation (target) -> cls_loss: 0.684534\taccuracy: 79.7475%\n",
            "Epoch 40 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.014268\tcls_loss: 0.013503\tk_loss: 0.554921\tk: 0.744930\tlat_loss: 0.020017\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.032295\tcls_loss: 0.031531\tk_loss: 0.555418\tk: 0.745263\tlat_loss: 0.018602\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.034098\tcls_loss: 0.033334\tk_loss: 0.556079\tk: 0.745707\tlat_loss: 0.018193\t\n",
            "Validation (source) -> cls_loss: 0.042850\taccuracy: 98.7933%\n",
            "Validation (target) -> cls_loss: 0.570661\taccuracy: 84.0834%\n",
            "Epoch 41 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.029755\tcls_loss: 0.028990\tk_loss: 0.556130\tk: 0.745741\tlat_loss: 0.019301\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.002208\tcls_loss: 0.001445\tk_loss: 0.556189\tk: 0.745781\tlat_loss: 0.017494\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.011034\tcls_loss: 0.010269\tk_loss: 0.556765\tk: 0.746167\tlat_loss: 0.019392\t\n",
            "Validation (source) -> cls_loss: 0.039912\taccuracy: 98.7533%\n",
            "Validation (target) -> cls_loss: 0.548843\taccuracy: 83.2053%\n",
            "Epoch 42 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.012000\tcls_loss: 0.011235\tk_loss: 0.556799\tk: 0.746190\tlat_loss: 0.018445\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.016775\tcls_loss: 0.016007\tk_loss: 0.557107\tk: 0.746396\tlat_loss: 0.021685\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.020370\tcls_loss: 0.019607\tk_loss: 0.556378\tk: 0.745908\tlat_loss: 0.017214\t\n",
            "Validation (source) -> cls_loss: 0.039022\taccuracy: 98.9133%\n",
            "Validation (target) -> cls_loss: 0.648975\taccuracy: 80.7355%\n",
            "Epoch 43 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.041060\tcls_loss: 0.040294\tk_loss: 0.556388\tk: 0.745914\tlat_loss: 0.019134\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.008757\tcls_loss: 0.007992\tk_loss: 0.556274\tk: 0.745838\tlat_loss: 0.018801\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.003426\tcls_loss: 0.002661\tk_loss: 0.556053\tk: 0.745689\tlat_loss: 0.019136\t\n",
            "Validation (source) -> cls_loss: 0.043290\taccuracy: 98.8933%\n",
            "Validation (target) -> cls_loss: 0.613093\taccuracy: 81.8332%\n",
            "Epoch 44 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.009616\tcls_loss: 0.008850\tk_loss: 0.556133\tk: 0.745743\tlat_loss: 0.020506\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.049116\tcls_loss: 0.048348\tk_loss: 0.556570\tk: 0.746036\tlat_loss: 0.021864\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.017084\tcls_loss: 0.016319\tk_loss: 0.557311\tk: 0.746532\tlat_loss: 0.018936\t\n",
            "Validation (source) -> cls_loss: 0.045297\taccuracy: 98.7800%\n",
            "Validation (target) -> cls_loss: 0.634630\taccuracy: 83.3699%\n",
            "Epoch 45 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.004957\tcls_loss: 0.004191\tk_loss: 0.557447\tk: 0.746624\tlat_loss: 0.019250\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.011632\tcls_loss: 0.010866\tk_loss: 0.559265\tk: 0.747840\tlat_loss: 0.017727\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.016453\tcls_loss: 0.015685\tk_loss: 0.560387\tk: 0.748590\tlat_loss: 0.019370\t\n",
            "Validation (source) -> cls_loss: 0.040703\taccuracy: 98.8400%\n",
            "Validation (target) -> cls_loss: 0.567513\taccuracy: 83.4248%\n",
            "Epoch 46 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.007972\tcls_loss: 0.007203\tk_loss: 0.560300\tk: 0.748532\tlat_loss: 0.020236\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.047849\tcls_loss: 0.047079\tk_loss: 0.561848\tk: 0.749565\tlat_loss: 0.020347\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.013518\tcls_loss: 0.012746\tk_loss: 0.562311\tk: 0.749874\tlat_loss: 0.021791\t\n",
            "Validation (source) -> cls_loss: 0.045402\taccuracy: 98.6733%\n",
            "Validation (target) -> cls_loss: 0.726337\taccuracy: 75.0823%\n",
            "Epoch 47 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.013785\tcls_loss: 0.013013\tk_loss: 0.562219\tk: 0.749812\tlat_loss: 0.022903\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.011326\tcls_loss: 0.010554\tk_loss: 0.562053\tk: 0.749702\tlat_loss: 0.022826\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.026977\tcls_loss: 0.026207\tk_loss: 0.564632\tk: 0.751420\tlat_loss: 0.019295\t\n",
            "Validation (source) -> cls_loss: 0.042034\taccuracy: 98.9267%\n",
            "Validation (target) -> cls_loss: 0.745911\taccuracy: 79.1987%\n",
            "Epoch 48 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.003845\tcls_loss: 0.003074\tk_loss: 0.564938\tk: 0.751624\tlat_loss: 0.019749\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.005146\tcls_loss: 0.004375\tk_loss: 0.565736\tk: 0.752154\tlat_loss: 0.018485\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.009428\tcls_loss: 0.008655\tk_loss: 0.566483\tk: 0.752650\tlat_loss: 0.020329\t\n",
            "Validation (source) -> cls_loss: 0.050416\taccuracy: 98.7200%\n",
            "Validation (target) -> cls_loss: 0.728003\taccuracy: 79.8024%\n",
            "Epoch 49 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.005438\tcls_loss: 0.004665\tk_loss: 0.566474\tk: 0.752644\tlat_loss: 0.019702\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.005649\tcls_loss: 0.004879\tk_loss: 0.565870\tk: 0.752243\tlat_loss: 0.016978\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.016375\tcls_loss: 0.015599\tk_loss: 0.566032\tk: 0.752351\tlat_loss: 0.023322\t\n",
            "Validation (source) -> cls_loss: 0.043634\taccuracy: 98.7867%\n",
            "Validation (target) -> cls_loss: 0.750478\taccuracy: 80.1866%\n",
            "Epoch 50 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.001622\tcls_loss: 0.000846\tk_loss: 0.565963\tk: 0.752305\tlat_loss: 0.023708\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.012205\tcls_loss: 0.011431\tk_loss: 0.566634\tk: 0.752751\tlat_loss: 0.021811\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.013641\tcls_loss: 0.012868\tk_loss: 0.567206\tk: 0.753131\tlat_loss: 0.020373\t\n",
            "Validation (source) -> cls_loss: 0.049204\taccuracy: 98.5267%\n",
            "Validation (target) -> cls_loss: 0.605216\taccuracy: 82.9857%\n",
            "Test (source) -> cls_loss: 0.039422\taccuracy: 98.7200%\n",
            "Test (target) -> cls_loss: 0.697286\taccuracy: 80.3687%\n",
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "MyModel                                  [128, 10]                 --\n",
            "├─FeatureExtractor: 1-1                  [128, 64, 3, 3]           --\n",
            "│    └─ModuleList: 2-1                   --                        --\n",
            "│    │    └─Sequential: 3-1              [128, 16, 14, 14]         160\n",
            "│    │    └─Sequential: 3-2              [128, 32, 7, 7]           4,640\n",
            "│    │    └─Sequential: 3-3              [128, 64, 3, 3]           18,496\n",
            "├─DimensionReducer: 1-2                  [128, 576]                667,010\n",
            "├─ClassRegressor: 1-3                    [128, 10]                 --\n",
            "│    └─ModuleList: 2-2                   --                        --\n",
            "│    │    └─Sequential: 3-4              [128, 128]                73,856\n",
            "│    │    └─Sequential: 3-5              [128, 64]                 8,256\n",
            "│    └─Linear: 2-3                       [128, 10]                 650\n",
            "==========================================================================================\n",
            "Total params: 773,068\n",
            "Trainable params: 773,068\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 259.07\n",
            "==========================================================================================\n",
            "Input size (MB): 0.40\n",
            "Forward/backward pass size (MB): 22.69\n",
            "Params size (MB): 0.42\n",
            "Estimated Total Size (MB): 23.51\n",
            "==========================================================================================\n",
            "Epoch 1 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 2.306099\tcls_loss: 2.305466\tk_loss: 0.393461\tk: 0.627265\tlat_loss: 0.005612\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 1.224280\tcls_loss: 1.223645\tk_loss: 0.393433\tk: 0.627242\tlat_loss: 0.007772\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.479361\tcls_loss: 0.478718\tk_loss: 0.392307\tk: 0.626344\tlat_loss: 0.016479\t\n",
            "Validation (source) -> cls_loss: 0.401661\taccuracy: 87.9200%\n",
            "Validation (target) -> cls_loss: 1.342006\taccuracy: 58.5071%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 2 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.308390\tcls_loss: 0.307747\tk_loss: 0.392151\tk: 0.626219\tlat_loss: 0.016738\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.211179\tcls_loss: 0.210541\tk_loss: 0.389448\tk: 0.624058\tlat_loss: 0.014027\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.176361\tcls_loss: 0.175722\tk_loss: 0.389254\tk: 0.623902\tlat_loss: 0.015228\t\n",
            "Validation (source) -> cls_loss: 0.174354\taccuracy: 94.7933%\n",
            "Validation (target) -> cls_loss: 0.789902\taccuracy: 71.6795%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 3 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.139228\tcls_loss: 0.138588\tk_loss: 0.389556\tk: 0.624144\tlat_loss: 0.015288\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.153983\tcls_loss: 0.153339\tk_loss: 0.393104\tk: 0.626980\tlat_loss: 0.016566\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.190585\tcls_loss: 0.189940\tk_loss: 0.395407\tk: 0.628814\tlat_loss: 0.016031\t\n",
            "Validation (source) -> cls_loss: 0.133112\taccuracy: 95.8333%\n",
            "Validation (target) -> cls_loss: 0.997865\taccuracy: 68.1120%\n",
            "Epoch 4 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.150435\tcls_loss: 0.149790\tk_loss: 0.395557\tk: 0.628933\tlat_loss: 0.015927\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.136596\tcls_loss: 0.135948\tk_loss: 0.398068\tk: 0.630927\tlat_loss: 0.017284\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.207397\tcls_loss: 0.206747\tk_loss: 0.399631\tk: 0.632164\tlat_loss: 0.017335\t\n",
            "Validation (source) -> cls_loss: 0.106161\taccuracy: 96.7600%\n",
            "Validation (target) -> cls_loss: 1.138435\taccuracy: 70.8013%\n",
            "Epoch 5 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.135063\tcls_loss: 0.134415\tk_loss: 0.399764\tk: 0.632269\tlat_loss: 0.015526\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.096367\tcls_loss: 0.095715\tk_loss: 0.401508\tk: 0.633647\tlat_loss: 0.018825\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.121128\tcls_loss: 0.120473\tk_loss: 0.403603\tk: 0.635297\tlat_loss: 0.019685\t\n",
            "Validation (source) -> cls_loss: 0.092055\taccuracy: 97.0933%\n",
            "Validation (target) -> cls_loss: 1.201085\taccuracy: 70.4720%\n",
            "Epoch 6 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.083728\tcls_loss: 0.083071\tk_loss: 0.403757\tk: 0.635419\tlat_loss: 0.020739\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.047171\tcls_loss: 0.046515\tk_loss: 0.405139\tk: 0.636505\tlat_loss: 0.019648\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.036120\tcls_loss: 0.035465\tk_loss: 0.405098\tk: 0.636473\tlat_loss: 0.018802\t\n",
            "Validation (source) -> cls_loss: 0.087505\taccuracy: 97.2467%\n",
            "Validation (target) -> cls_loss: 1.009365\taccuracy: 70.9660%\n",
            "Epoch 7 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.089473\tcls_loss: 0.088816\tk_loss: 0.405053\tk: 0.636438\tlat_loss: 0.020770\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.068747\tcls_loss: 0.068087\tk_loss: 0.405012\tk: 0.636406\tlat_loss: 0.023488\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.056659\tcls_loss: 0.055995\tk_loss: 0.405069\tk: 0.636451\tlat_loss: 0.027277\t\n",
            "Validation (source) -> cls_loss: 0.081256\taccuracy: 97.5733%\n",
            "Validation (target) -> cls_loss: 1.246709\taccuracy: 69.8683%\n",
            "Epoch 8 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.102872\tcls_loss: 0.102208\tk_loss: 0.405110\tk: 0.636483\tlat_loss: 0.026899\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.066218\tcls_loss: 0.065556\tk_loss: 0.405637\tk: 0.636896\tlat_loss: 0.024991\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.027740\tcls_loss: 0.027081\tk_loss: 0.406479\tk: 0.637557\tlat_loss: 0.021491\t\n",
            "Validation (source) -> cls_loss: 0.071618\taccuracy: 97.8733%\n",
            "Validation (target) -> cls_loss: 0.657305\taccuracy: 76.0703%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 9 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.129830\tcls_loss: 0.129171\tk_loss: 0.406595\tk: 0.637648\tlat_loss: 0.020922\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.094705\tcls_loss: 0.094042\tk_loss: 0.407643\tk: 0.638469\tlat_loss: 0.024664\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.029519\tcls_loss: 0.028852\tk_loss: 0.408779\tk: 0.639358\tlat_loss: 0.028105\t\n",
            "Validation (source) -> cls_loss: 0.073292\taccuracy: 97.7800%\n",
            "Validation (target) -> cls_loss: 1.134507\taccuracy: 70.6367%\n",
            "Epoch 10 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.039154\tcls_loss: 0.038487\tk_loss: 0.409066\tk: 0.639582\tlat_loss: 0.027854\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.087099\tcls_loss: 0.086431\tk_loss: 0.410573\tk: 0.640759\tlat_loss: 0.026651\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.094774\tcls_loss: 0.094110\tk_loss: 0.410778\tk: 0.640919\tlat_loss: 0.022773\t\n",
            "Validation (source) -> cls_loss: 0.072314\taccuracy: 97.7400%\n",
            "Validation (target) -> cls_loss: 0.909398\taccuracy: 69.9232%\n",
            "Epoch 11 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.060200\tcls_loss: 0.059534\tk_loss: 0.410724\tk: 0.640878\tlat_loss: 0.025965\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.047915\tcls_loss: 0.047253\tk_loss: 0.410145\tk: 0.640425\tlat_loss: 0.021529\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.070753\tcls_loss: 0.070083\tk_loss: 0.411779\tk: 0.641700\tlat_loss: 0.028157\t\n",
            "Validation (source) -> cls_loss: 0.062536\taccuracy: 98.1200%\n",
            "Validation (target) -> cls_loss: 1.247237\taccuracy: 70.1976%\n",
            "Epoch 12 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.038959\tcls_loss: 0.038289\tk_loss: 0.411898\tk: 0.641793\tlat_loss: 0.028287\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.036714\tcls_loss: 0.036050\tk_loss: 0.408654\tk: 0.639261\tlat_loss: 0.024193\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.024739\tcls_loss: 0.024078\tk_loss: 0.407784\tk: 0.638580\tlat_loss: 0.022068\t\n",
            "Validation (source) -> cls_loss: 0.070774\taccuracy: 97.8200%\n",
            "Validation (target) -> cls_loss: 0.589974\taccuracy: 78.7047%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 13 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.011529\tcls_loss: 0.010867\tk_loss: 0.407833\tk: 0.638618\tlat_loss: 0.022956\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.079806\tcls_loss: 0.079143\tk_loss: 0.407969\tk: 0.638725\tlat_loss: 0.025097\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.064390\tcls_loss: 0.063722\tk_loss: 0.407939\tk: 0.638701\tlat_loss: 0.028919\t\n",
            "Validation (source) -> cls_loss: 0.063399\taccuracy: 97.9867%\n",
            "Validation (target) -> cls_loss: 0.767741\taccuracy: 72.6125%\n",
            "Epoch 14 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.078875\tcls_loss: 0.078209\tk_loss: 0.408025\tk: 0.638768\tlat_loss: 0.027789\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.018872\tcls_loss: 0.018203\tk_loss: 0.409502\tk: 0.639923\tlat_loss: 0.028752\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.090518\tcls_loss: 0.089849\tk_loss: 0.409155\tk: 0.639652\tlat_loss: 0.029946\t\n",
            "Validation (source) -> cls_loss: 0.065451\taccuracy: 98.0267%\n",
            "Validation (target) -> cls_loss: 0.613989\taccuracy: 80.0768%\n",
            "Epoch 15 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.020352\tcls_loss: 0.019682\tk_loss: 0.408837\tk: 0.639403\tlat_loss: 0.030537\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.010998\tcls_loss: 0.010331\tk_loss: 0.408612\tk: 0.639228\tlat_loss: 0.028164\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.026506\tcls_loss: 0.025838\tk_loss: 0.407900\tk: 0.638671\tlat_loss: 0.029852\t\n",
            "Validation (source) -> cls_loss: 0.056001\taccuracy: 98.2400%\n",
            "Validation (target) -> cls_loss: 0.952524\taccuracy: 68.7157%\n",
            "Epoch 16 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.039068\tcls_loss: 0.038402\tk_loss: 0.407762\tk: 0.638562\tlat_loss: 0.026915\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.025526\tcls_loss: 0.024856\tk_loss: 0.408694\tk: 0.639292\tlat_loss: 0.030634\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.018054\tcls_loss: 0.017384\tk_loss: 0.410099\tk: 0.640390\tlat_loss: 0.030180\t\n",
            "Validation (source) -> cls_loss: 0.060407\taccuracy: 98.2133%\n",
            "Validation (target) -> cls_loss: 0.932684\taccuracy: 72.1186%\n",
            "Epoch 17 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.118937\tcls_loss: 0.118269\tk_loss: 0.410324\tk: 0.640565\tlat_loss: 0.027574\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.029957\tcls_loss: 0.029287\tk_loss: 0.410429\tk: 0.640647\tlat_loss: 0.029300\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.072314\tcls_loss: 0.071641\tk_loss: 0.412286\tk: 0.642095\tlat_loss: 0.030641\t\n",
            "Validation (source) -> cls_loss: 0.059934\taccuracy: 98.1733%\n",
            "Validation (target) -> cls_loss: 0.855148\taccuracy: 77.0033%\n",
            "Epoch 18 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.024154\tcls_loss: 0.023483\tk_loss: 0.412215\tk: 0.642039\tlat_loss: 0.028608\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.033035\tcls_loss: 0.032366\tk_loss: 0.411980\tk: 0.641856\tlat_loss: 0.026685\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.006739\tcls_loss: 0.006070\tk_loss: 0.412104\tk: 0.641953\tlat_loss: 0.027820\t\n",
            "Validation (source) -> cls_loss: 0.053730\taccuracy: 98.3333%\n",
            "Validation (target) -> cls_loss: 0.885094\taccuracy: 73.0516%\n",
            "Epoch 19 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.035719\tcls_loss: 0.035049\tk_loss: 0.412025\tk: 0.641892\tlat_loss: 0.028429\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.018224\tcls_loss: 0.017554\tk_loss: 0.412152\tk: 0.641991\tlat_loss: 0.028175\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.006029\tcls_loss: 0.005362\tk_loss: 0.412345\tk: 0.642141\tlat_loss: 0.025600\t\n",
            "Validation (source) -> cls_loss: 0.051047\taccuracy: 98.4667%\n",
            "Validation (target) -> cls_loss: 0.722943\taccuracy: 79.1438%\n",
            "Epoch 20 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.096777\tcls_loss: 0.096110\tk_loss: 0.412365\tk: 0.642157\tlat_loss: 0.024675\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.033271\tcls_loss: 0.032602\tk_loss: 0.413290\tk: 0.642877\tlat_loss: 0.026742\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.026462\tcls_loss: 0.025796\tk_loss: 0.413386\tk: 0.642951\tlat_loss: 0.022768\t\n",
            "Validation (source) -> cls_loss: 0.054633\taccuracy: 98.4133%\n",
            "Validation (target) -> cls_loss: 0.660278\taccuracy: 78.3754%\n",
            "Epoch 21 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.016210\tcls_loss: 0.015543\tk_loss: 0.413476\tk: 0.643021\tlat_loss: 0.023835\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.024152\tcls_loss: 0.023483\tk_loss: 0.413487\tk: 0.643030\tlat_loss: 0.025893\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.019039\tcls_loss: 0.018370\tk_loss: 0.412666\tk: 0.642391\tlat_loss: 0.026738\t\n",
            "Validation (source) -> cls_loss: 0.053358\taccuracy: 98.4467%\n",
            "Validation (target) -> cls_loss: 0.766008\taccuracy: 77.4973%\n",
            "Epoch 22 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.025585\tcls_loss: 0.024916\tk_loss: 0.412600\tk: 0.642339\tlat_loss: 0.026204\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.009032\tcls_loss: 0.008363\tk_loss: 0.413837\tk: 0.643301\tlat_loss: 0.025085\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.006193\tcls_loss: 0.005524\tk_loss: 0.415619\tk: 0.644686\tlat_loss: 0.023793\t\n",
            "Validation (source) -> cls_loss: 0.046241\taccuracy: 98.6400%\n",
            "Validation (target) -> cls_loss: 0.754816\taccuracy: 76.2898%\n",
            "Epoch 23 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.055252\tcls_loss: 0.054583\tk_loss: 0.415734\tk: 0.644774\tlat_loss: 0.024255\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.006210\tcls_loss: 0.005540\tk_loss: 0.416338\tk: 0.645243\tlat_loss: 0.024730\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.065121\tcls_loss: 0.064449\tk_loss: 0.416560\tk: 0.645414\tlat_loss: 0.026257\t\n",
            "Validation (source) -> cls_loss: 0.050402\taccuracy: 98.5067%\n",
            "Validation (target) -> cls_loss: 0.623176\taccuracy: 79.6926%\n",
            "Epoch 24 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.035676\tcls_loss: 0.035005\tk_loss: 0.416573\tk: 0.645424\tlat_loss: 0.024971\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.032385\tcls_loss: 0.031718\tk_loss: 0.417486\tk: 0.646131\tlat_loss: 0.021717\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.040189\tcls_loss: 0.039519\tk_loss: 0.418536\tk: 0.646943\tlat_loss: 0.023270\t\n",
            "Validation (source) -> cls_loss: 0.053391\taccuracy: 98.5133%\n",
            "Validation (target) -> cls_loss: 0.654029\taccuracy: 79.6926%\n",
            "Epoch 25 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.027457\tcls_loss: 0.026787\tk_loss: 0.418697\tk: 0.647068\tlat_loss: 0.023066\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.030008\tcls_loss: 0.029333\tk_loss: 0.422712\tk: 0.650163\tlat_loss: 0.024703\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.012270\tcls_loss: 0.011592\tk_loss: 0.425213\tk: 0.652084\tlat_loss: 0.026122\t\n",
            "Validation (source) -> cls_loss: 0.048519\taccuracy: 98.6533%\n",
            "Validation (target) -> cls_loss: 0.708420\taccuracy: 77.4424%\n",
            "Epoch 26 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.014517\tcls_loss: 0.013836\tk_loss: 0.425338\tk: 0.652179\tlat_loss: 0.028655\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.056484\tcls_loss: 0.055804\tk_loss: 0.426135\tk: 0.652790\tlat_loss: 0.026901\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.072653\tcls_loss: 0.071976\tk_loss: 0.426780\tk: 0.653284\tlat_loss: 0.024573\t\n",
            "Validation (source) -> cls_loss: 0.045449\taccuracy: 98.6067%\n",
            "Validation (target) -> cls_loss: 0.627942\taccuracy: 80.6257%\n",
            "Epoch 27 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.094954\tcls_loss: 0.094275\tk_loss: 0.426875\tk: 0.653357\tlat_loss: 0.025269\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.018667\tcls_loss: 0.017988\tk_loss: 0.427372\tk: 0.653737\tlat_loss: 0.025648\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.042379\tcls_loss: 0.041695\tk_loss: 0.428163\tk: 0.654342\tlat_loss: 0.029495\t\n",
            "Validation (source) -> cls_loss: 0.046185\taccuracy: 98.7200%\n",
            "Validation (target) -> cls_loss: 1.092846\taccuracy: 71.4050%\n",
            "Epoch 28 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.016607\tcls_loss: 0.015922\tk_loss: 0.428158\tk: 0.654338\tlat_loss: 0.030285\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.019620\tcls_loss: 0.018940\tk_loss: 0.428384\tk: 0.654511\tlat_loss: 0.026000\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.003798\tcls_loss: 0.003118\tk_loss: 0.428495\tk: 0.654596\tlat_loss: 0.025495\t\n",
            "Validation (source) -> cls_loss: 0.043682\taccuracy: 98.6067%\n",
            "Validation (target) -> cls_loss: 0.942297\taccuracy: 70.2525%\n",
            "Epoch 29 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.004708\tcls_loss: 0.004027\tk_loss: 0.428513\tk: 0.654609\tlat_loss: 0.026619\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.104592\tcls_loss: 0.103911\tk_loss: 0.429125\tk: 0.655077\tlat_loss: 0.025451\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.031335\tcls_loss: 0.030654\tk_loss: 0.431604\tk: 0.656966\tlat_loss: 0.024545\t\n",
            "Validation (source) -> cls_loss: 0.047603\taccuracy: 98.6267%\n",
            "Validation (target) -> cls_loss: 0.584238\taccuracy: 79.9671%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 30 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.022730\tcls_loss: 0.022049\tk_loss: 0.431739\tk: 0.657069\tlat_loss: 0.024000\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.082938\tcls_loss: 0.082256\tk_loss: 0.433476\tk: 0.658389\tlat_loss: 0.023705\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.006442\tcls_loss: 0.005757\tk_loss: 0.434946\tk: 0.659504\tlat_loss: 0.025493\t\n",
            "Validation (source) -> cls_loss: 0.050071\taccuracy: 98.5667%\n",
            "Validation (target) -> cls_loss: 0.621109\taccuracy: 80.3513%\n",
            "Epoch 31 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.012644\tcls_loss: 0.011960\tk_loss: 0.435026\tk: 0.659565\tlat_loss: 0.024241\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.041522\tcls_loss: 0.040838\tk_loss: 0.436113\tk: 0.660388\tlat_loss: 0.023934\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.021127\tcls_loss: 0.020438\tk_loss: 0.436327\tk: 0.660551\tlat_loss: 0.028103\t\n",
            "Validation (source) -> cls_loss: 0.050881\taccuracy: 98.6000%\n",
            "Validation (target) -> cls_loss: 0.617818\taccuracy: 80.6806%\n",
            "Epoch 32 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.013629\tcls_loss: 0.012940\tk_loss: 0.436384\tk: 0.660593\tlat_loss: 0.028991\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.012260\tcls_loss: 0.011573\tk_loss: 0.437569\tk: 0.661490\tlat_loss: 0.024837\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.012020\tcls_loss: 0.011334\tk_loss: 0.439699\tk: 0.663098\tlat_loss: 0.022683\t\n",
            "Validation (source) -> cls_loss: 0.044018\taccuracy: 98.6533%\n",
            "Validation (target) -> cls_loss: 0.501028\taccuracy: 82.7662%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 33 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.013554\tcls_loss: 0.012869\tk_loss: 0.439863\tk: 0.663222\tlat_loss: 0.021140\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.018659\tcls_loss: 0.017973\tk_loss: 0.442967\tk: 0.665557\tlat_loss: 0.020710\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.014998\tcls_loss: 0.014309\tk_loss: 0.444532\tk: 0.666732\tlat_loss: 0.021855\t\n",
            "Validation (source) -> cls_loss: 0.042665\taccuracy: 98.7333%\n",
            "Validation (target) -> cls_loss: 0.778281\taccuracy: 74.9726%\n",
            "Epoch 34 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.023542\tcls_loss: 0.022854\tk_loss: 0.444624\tk: 0.666801\tlat_loss: 0.021264\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.007103\tcls_loss: 0.006412\tk_loss: 0.444998\tk: 0.667082\tlat_loss: 0.024671\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.006734\tcls_loss: 0.006041\tk_loss: 0.444224\tk: 0.666501\tlat_loss: 0.026002\t\n",
            "Validation (source) -> cls_loss: 0.045840\taccuracy: 98.6600%\n",
            "Validation (target) -> cls_loss: 0.925706\taccuracy: 70.4720%\n",
            "Epoch 35 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.023950\tcls_loss: 0.023255\tk_loss: 0.444236\tk: 0.666510\tlat_loss: 0.027935\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.042186\tcls_loss: 0.041495\tk_loss: 0.443394\tk: 0.665879\tlat_loss: 0.025373\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.004316\tcls_loss: 0.003621\tk_loss: 0.445116\tk: 0.667170\tlat_loss: 0.028360\t\n",
            "Validation (source) -> cls_loss: 0.056845\taccuracy: 98.3333%\n",
            "Validation (target) -> cls_loss: 0.820364\taccuracy: 74.6432%\n",
            "Epoch 36 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.005221\tcls_loss: 0.004524\tk_loss: 0.445219\tk: 0.667247\tlat_loss: 0.029532\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.009265\tcls_loss: 0.008574\tk_loss: 0.446086\tk: 0.667897\tlat_loss: 0.023158\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.008043\tcls_loss: 0.007352\tk_loss: 0.445569\tk: 0.667509\tlat_loss: 0.023417\t\n",
            "Validation (source) -> cls_loss: 0.045663\taccuracy: 98.6667%\n",
            "Validation (target) -> cls_loss: 0.614240\taccuracy: 80.0220%\n",
            "Epoch 37 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.005695\tcls_loss: 0.005004\tk_loss: 0.445558\tk: 0.667501\tlat_loss: 0.023829\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.044738\tcls_loss: 0.044043\tk_loss: 0.445436\tk: 0.667410\tlat_loss: 0.027363\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.071869\tcls_loss: 0.071177\tk_loss: 0.445569\tk: 0.667510\tlat_loss: 0.024289\t\n",
            "Validation (source) -> cls_loss: 0.059543\taccuracy: 98.3467%\n",
            "Validation (target) -> cls_loss: 0.598636\taccuracy: 81.8880%\n",
            "Epoch 38 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.005143\tcls_loss: 0.004451\tk_loss: 0.445626\tk: 0.667552\tlat_loss: 0.024650\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.015121\tcls_loss: 0.014430\tk_loss: 0.446138\tk: 0.667936\tlat_loss: 0.023452\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.008347\tcls_loss: 0.007657\tk_loss: 0.446909\tk: 0.668512\tlat_loss: 0.021348\t\n",
            "Validation (source) -> cls_loss: 0.044368\taccuracy: 98.7133%\n",
            "Validation (target) -> cls_loss: 0.508530\taccuracy: 83.4797%\n",
            "Epoch 39 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.010454\tcls_loss: 0.009764\tk_loss: 0.446934\tk: 0.668531\tlat_loss: 0.021236\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.033408\tcls_loss: 0.032715\tk_loss: 0.446769\tk: 0.668408\tlat_loss: 0.024394\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.008971\tcls_loss: 0.008271\tk_loss: 0.448076\tk: 0.669385\tlat_loss: 0.030593\t\n",
            "Validation (source) -> cls_loss: 0.050977\taccuracy: 98.5333%\n",
            "Validation (target) -> cls_loss: 0.940682\taccuracy: 73.4358%\n",
            "Epoch 40 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.003419\tcls_loss: 0.002718\tk_loss: 0.448325\tk: 0.669571\tlat_loss: 0.032018\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.001548\tcls_loss: 0.000851\tk_loss: 0.447931\tk: 0.669277\tlat_loss: 0.027745\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.017087\tcls_loss: 0.016392\tk_loss: 0.448372\tk: 0.669606\tlat_loss: 0.025319\t\n",
            "Validation (source) -> cls_loss: 0.047908\taccuracy: 98.5933%\n",
            "Validation (target) -> cls_loss: 0.683488\taccuracy: 75.6861%\n",
            "Epoch 41 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.019160\tcls_loss: 0.018467\tk_loss: 0.448537\tk: 0.669729\tlat_loss: 0.023434\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.021578\tcls_loss: 0.020885\tk_loss: 0.449541\tk: 0.670478\tlat_loss: 0.021838\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.041125\tcls_loss: 0.040430\tk_loss: 0.451346\tk: 0.671823\tlat_loss: 0.022627\t\n",
            "Validation (source) -> cls_loss: 0.042945\taccuracy: 98.7400%\n",
            "Validation (target) -> cls_loss: 0.691722\taccuracy: 78.2108%\n",
            "Epoch 42 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.017882\tcls_loss: 0.017184\tk_loss: 0.451476\tk: 0.671920\tlat_loss: 0.026474\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.005856\tcls_loss: 0.005161\tk_loss: 0.452161\tk: 0.672429\tlat_loss: 0.022710\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.036046\tcls_loss: 0.035348\tk_loss: 0.452884\tk: 0.672966\tlat_loss: 0.024583\t\n",
            "Validation (source) -> cls_loss: 0.045091\taccuracy: 98.6133%\n",
            "Validation (target) -> cls_loss: 0.553585\taccuracy: 81.9978%\n",
            "Epoch 43 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.004196\tcls_loss: 0.003500\tk_loss: 0.453062\tk: 0.673099\tlat_loss: 0.023147\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.011235\tcls_loss: 0.010538\tk_loss: 0.454719\tk: 0.674329\tlat_loss: 0.022922\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.012996\tcls_loss: 0.012298\tk_loss: 0.454798\tk: 0.674387\tlat_loss: 0.023742\t\n",
            "Validation (source) -> cls_loss: 0.048371\taccuracy: 98.6600%\n",
            "Validation (target) -> cls_loss: 0.912878\taccuracy: 74.2042%\n",
            "Epoch 44 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.007988\tcls_loss: 0.007289\tk_loss: 0.454847\tk: 0.674424\tlat_loss: 0.024340\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.007927\tcls_loss: 0.007225\tk_loss: 0.455091\tk: 0.674605\tlat_loss: 0.027368\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.001687\tcls_loss: 0.000988\tk_loss: 0.455715\tk: 0.675067\tlat_loss: 0.023696\t\n",
            "Validation (source) -> cls_loss: 0.047238\taccuracy: 98.6333%\n",
            "Validation (target) -> cls_loss: 0.503831\taccuracy: 84.4676%\n",
            "Epoch 45 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.034672\tcls_loss: 0.033972\tk_loss: 0.455775\tk: 0.675111\tlat_loss: 0.024393\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.001825\tcls_loss: 0.001124\tk_loss: 0.456518\tk: 0.675661\tlat_loss: 0.025099\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.017852\tcls_loss: 0.017153\tk_loss: 0.457293\tk: 0.676234\tlat_loss: 0.023232\t\n",
            "Validation (source) -> cls_loss: 0.042409\taccuracy: 98.8600%\n",
            "Validation (target) -> cls_loss: 0.721920\taccuracy: 79.6378%\n",
            "Epoch 46 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.036986\tcls_loss: 0.036284\tk_loss: 0.457382\tk: 0.676300\tlat_loss: 0.025842\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.075976\tcls_loss: 0.075278\tk_loss: 0.458020\tk: 0.676771\tlat_loss: 0.020881\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.007266\tcls_loss: 0.006564\tk_loss: 0.458790\tk: 0.677341\tlat_loss: 0.024324\t\n",
            "Validation (source) -> cls_loss: 0.042503\taccuracy: 98.8200%\n",
            "Validation (target) -> cls_loss: 0.645249\taccuracy: 80.8452%\n",
            "Epoch 47 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.022877\tcls_loss: 0.022177\tk_loss: 0.458831\tk: 0.677371\tlat_loss: 0.023287\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.009258\tcls_loss: 0.008557\tk_loss: 0.459050\tk: 0.677532\tlat_loss: 0.022935\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.046263\tcls_loss: 0.045559\tk_loss: 0.460074\tk: 0.678288\tlat_loss: 0.025716\t\n",
            "Validation (source) -> cls_loss: 0.042862\taccuracy: 98.8267%\n",
            "Validation (target) -> cls_loss: 0.721879\taccuracy: 78.4303%\n",
            "Epoch 48 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.015003\tcls_loss: 0.014302\tk_loss: 0.460216\tk: 0.678392\tlat_loss: 0.022290\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.004066\tcls_loss: 0.003363\tk_loss: 0.461403\tk: 0.679266\tlat_loss: 0.022858\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.019304\tcls_loss: 0.018597\tk_loss: 0.461617\tk: 0.679424\tlat_loss: 0.027419\t\n",
            "Validation (source) -> cls_loss: 0.041074\taccuracy: 98.8800%\n",
            "Validation (target) -> cls_loss: 0.595436\taccuracy: 82.7113%\n",
            "Epoch 49 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.023800\tcls_loss: 0.023094\tk_loss: 0.461809\tk: 0.679566\tlat_loss: 0.027068\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.034352\tcls_loss: 0.033643\tk_loss: 0.462016\tk: 0.679718\tlat_loss: 0.029197\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.040713\tcls_loss: 0.040006\tk_loss: 0.461304\tk: 0.679194\tlat_loss: 0.027996\t\n",
            "Validation (source) -> cls_loss: 0.051693\taccuracy: 98.6200%\n",
            "Validation (target) -> cls_loss: 0.759613\taccuracy: 78.3754%\n",
            "Epoch 50 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.067197\tcls_loss: 0.066493\tk_loss: 0.461033\tk: 0.678994\tlat_loss: 0.025909\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.016048\tcls_loss: 0.015347\tk_loss: 0.460940\tk: 0.678926\tlat_loss: 0.022897\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.015184\tcls_loss: 0.014475\tk_loss: 0.460501\tk: 0.678602\tlat_loss: 0.029798\t\n",
            "Validation (source) -> cls_loss: 0.049827\taccuracy: 98.7133%\n",
            "Validation (target) -> cls_loss: 1.013174\taccuracy: 73.9297%\n",
            "Test (source) -> cls_loss: 0.037754\taccuracy: 98.7900%\n",
            "Test (target) -> cls_loss: 0.655438\taccuracy: 80.0698%\n",
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "MyModel                                  [128, 10]                 --\n",
            "├─FeatureExtractor: 1-1                  [128, 64, 3, 3]           --\n",
            "│    └─ModuleList: 2-1                   --                        --\n",
            "│    │    └─Sequential: 3-1              [128, 16, 14, 14]         160\n",
            "│    │    └─Sequential: 3-2              [128, 32, 7, 7]           4,640\n",
            "│    │    └─Sequential: 3-3              [128, 64, 3, 3]           18,496\n",
            "├─DimensionReducer: 1-2                  [128, 576]                667,010\n",
            "├─ClassRegressor: 1-3                    [128, 10]                 --\n",
            "│    └─ModuleList: 2-2                   --                        --\n",
            "│    │    └─Sequential: 3-4              [128, 128]                73,856\n",
            "│    │    └─Sequential: 3-5              [128, 64]                 8,256\n",
            "│    └─Linear: 2-3                       [128, 10]                 650\n",
            "==========================================================================================\n",
            "Total params: 773,068\n",
            "Trainable params: 773,068\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 259.07\n",
            "==========================================================================================\n",
            "Input size (MB): 0.40\n",
            "Forward/backward pass size (MB): 22.69\n",
            "Params size (MB): 0.42\n",
            "Estimated Total Size (MB): 23.51\n",
            "==========================================================================================\n",
            "Epoch 1 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 2.314509\tcls_loss: 2.314440\tk_loss: 0.003564\tk: 0.059700\tlat_loss: 0.008887\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 1.277376\tcls_loss: 1.276931\tk_loss: 0.003672\tk: 0.060593\tlat_loss: 0.384677\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.678190\tcls_loss: 0.675183\tk_loss: 0.003834\tk: 0.061922\tlat_loss: 2.945039\t\n",
            "Validation (source) -> cls_loss: 0.610227\taccuracy: 79.6667%\n",
            "Validation (target) -> cls_loss: 1.184268\taccuracy: 62.1844%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 2 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.671522\tcls_loss: 0.668778\tk_loss: 0.003846\tk: 0.062019\tlat_loss: 2.682280\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.519856\tcls_loss: 0.517179\tk_loss: 0.003953\tk: 0.062874\tlat_loss: 2.614904\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.330647\tcls_loss: 0.328269\tk_loss: 0.004063\tk: 0.063744\tlat_loss: 2.314356\t\n",
            "Validation (source) -> cls_loss: 0.306469\taccuracy: 90.7333%\n",
            "Validation (target) -> cls_loss: 0.860624\taccuracy: 72.8321%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 3 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.397622\tcls_loss: 0.395512\tk_loss: 0.004069\tk: 0.063790\tlat_loss: 2.046269\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.326971\tcls_loss: 0.325042\tk_loss: 0.004151\tk: 0.064426\tlat_loss: 1.864586\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.198015\tcls_loss: 0.196039\tk_loss: 0.004210\tk: 0.064884\tlat_loss: 1.910616\t\n",
            "Validation (source) -> cls_loss: 0.223664\taccuracy: 93.0733%\n",
            "Validation (target) -> cls_loss: 0.822884\taccuracy: 74.0395%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 4 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.131707\tcls_loss: 0.129939\tk_loss: 0.004216\tk: 0.064930\tlat_loss: 1.702706\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.139565\tcls_loss: 0.137295\tk_loss: 0.004247\tk: 0.065172\tlat_loss: 2.204931\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.210461\tcls_loss: 0.208516\tk_loss: 0.004279\tk: 0.065416\tlat_loss: 1.879176\t\n",
            "Validation (source) -> cls_loss: 0.173811\taccuracy: 94.5467%\n",
            "Validation (target) -> cls_loss: 0.950352\taccuracy: 70.5269%\n",
            "Epoch 5 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.183492\tcls_loss: 0.181260\tk_loss: 0.004285\tk: 0.065461\tlat_loss: 2.166022\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.220728\tcls_loss: 0.218919\tk_loss: 0.004302\tk: 0.065587\tlat_loss: 1.743584\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.146896\tcls_loss: 0.145141\tk_loss: 0.004319\tk: 0.065716\tlat_loss: 1.689399\t\n",
            "Validation (source) -> cls_loss: 0.164851\taccuracy: 95.0400%\n",
            "Validation (target) -> cls_loss: 0.901543\taccuracy: 70.4171%\n",
            "Epoch 6 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.128740\tcls_loss: 0.126996\tk_loss: 0.004322\tk: 0.065742\tlat_loss: 1.679019\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.118357\tcls_loss: 0.116597\tk_loss: 0.004347\tk: 0.065934\tlat_loss: 1.693765\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.089201\tcls_loss: 0.087569\tk_loss: 0.004391\tk: 0.066261\tlat_loss: 1.565895\t\n",
            "Validation (source) -> cls_loss: 0.147002\taccuracy: 95.6667%\n",
            "Validation (target) -> cls_loss: 0.914727\taccuracy: 72.8869%\n",
            "Epoch 7 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.062695\tcls_loss: 0.061150\tk_loss: 0.004393\tk: 0.066277\tlat_loss: 1.479010\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.213258\tcls_loss: 0.211594\tk_loss: 0.004420\tk: 0.066482\tlat_loss: 1.597476\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.161643\tcls_loss: 0.160225\tk_loss: 0.004454\tk: 0.066741\tlat_loss: 1.351962\t\n",
            "Validation (source) -> cls_loss: 0.129534\taccuracy: 96.2533%\n",
            "Validation (target) -> cls_loss: 0.880853\taccuracy: 72.2283%\n",
            "Epoch 8 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.102065\tcls_loss: 0.100630\tk_loss: 0.004457\tk: 0.066760\tlat_loss: 1.368925\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.153223\tcls_loss: 0.151659\tk_loss: 0.004484\tk: 0.066966\tlat_loss: 1.497686\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.075028\tcls_loss: 0.073443\tk_loss: 0.004522\tk: 0.067245\tlat_loss: 1.517922\t\n",
            "Validation (source) -> cls_loss: 0.137272\taccuracy: 95.7467%\n",
            "Validation (target) -> cls_loss: 0.928626\taccuracy: 72.3381%\n",
            "Epoch 9 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.184711\tcls_loss: 0.183107\tk_loss: 0.004525\tk: 0.067268\tlat_loss: 1.536741\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.101861\tcls_loss: 0.100159\tk_loss: 0.004562\tk: 0.067545\tlat_loss: 1.633980\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.149816\tcls_loss: 0.148493\tk_loss: 0.004593\tk: 0.067775\tlat_loss: 1.255187\t\n",
            "Validation (source) -> cls_loss: 0.124697\taccuracy: 96.2733%\n",
            "Validation (target) -> cls_loss: 0.906438\taccuracy: 68.6608%\n",
            "Epoch 10 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.109548\tcls_loss: 0.108277\tk_loss: 0.004598\tk: 0.067810\tlat_loss: 1.202853\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.170246\tcls_loss: 0.168801\tk_loss: 0.004642\tk: 0.068133\tlat_loss: 1.377397\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.118254\tcls_loss: 0.116870\tk_loss: 0.004680\tk: 0.068407\tlat_loss: 1.315708\t\n",
            "Validation (source) -> cls_loss: 0.109291\taccuracy: 96.6933%\n",
            "Validation (target) -> cls_loss: 0.927211\taccuracy: 71.6246%\n",
            "Epoch 11 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.106801\tcls_loss: 0.105240\tk_loss: 0.004685\tk: 0.068446\tlat_loss: 1.492796\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.091425\tcls_loss: 0.089964\tk_loss: 0.004734\tk: 0.068802\tlat_loss: 1.391785\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.040052\tcls_loss: 0.038628\tk_loss: 0.004782\tk: 0.069153\tlat_loss: 1.355086\t\n",
            "Validation (source) -> cls_loss: 0.105986\taccuracy: 96.7333%\n",
            "Validation (target) -> cls_loss: 0.828840\taccuracy: 72.0637%\n",
            "Epoch 12 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.027844\tcls_loss: 0.026460\tk_loss: 0.004786\tk: 0.069178\tlat_loss: 1.315355\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.040660\tcls_loss: 0.039177\tk_loss: 0.004807\tk: 0.069334\tlat_loss: 1.414091\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.084555\tcls_loss: 0.083035\tk_loss: 0.004840\tk: 0.069573\tlat_loss: 1.450723\t\n",
            "Validation (source) -> cls_loss: 0.096685\taccuracy: 97.1400%\n",
            "Validation (target) -> cls_loss: 0.979954\taccuracy: 69.6487%\n",
            "Epoch 13 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.066833\tcls_loss: 0.065309\tk_loss: 0.004844\tk: 0.069599\tlat_loss: 1.454102\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.144599\tcls_loss: 0.142747\tk_loss: 0.004867\tk: 0.069761\tlat_loss: 1.782484\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.102388\tcls_loss: 0.101215\tk_loss: 0.004918\tk: 0.070126\tlat_loss: 1.102797\t\n",
            "Validation (source) -> cls_loss: 0.092025\taccuracy: 97.3400%\n",
            "Validation (target) -> cls_loss: 1.101961\taccuracy: 67.6180%\n",
            "Epoch 14 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.083630\tcls_loss: 0.082369\tk_loss: 0.004924\tk: 0.070171\tlat_loss: 1.190947\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.084336\tcls_loss: 0.083047\tk_loss: 0.004984\tk: 0.070596\tlat_loss: 1.218970\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.011117\tcls_loss: 0.009654\tk_loss: 0.005055\tk: 0.071100\tlat_loss: 1.392486\t\n",
            "Validation (source) -> cls_loss: 0.092834\taccuracy: 97.3867%\n",
            "Validation (target) -> cls_loss: 0.891015\taccuracy: 75.1921%\n",
            "Epoch 15 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.061756\tcls_loss: 0.060263\tk_loss: 0.005060\tk: 0.071136\tlat_loss: 1.421933\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.074367\tcls_loss: 0.072839\tk_loss: 0.005109\tk: 0.071475\tlat_loss: 1.456003\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.068380\tcls_loss: 0.066890\tk_loss: 0.005143\tk: 0.071712\tlat_loss: 1.418044\t\n",
            "Validation (source) -> cls_loss: 0.119670\taccuracy: 96.5867%\n",
            "Validation (target) -> cls_loss: 0.925726\taccuracy: 72.7772%\n",
            "Epoch 16 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.064550\tcls_loss: 0.063107\tk_loss: 0.005148\tk: 0.071748\tlat_loss: 1.371496\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.042465\tcls_loss: 0.041370\tk_loss: 0.005167\tk: 0.071879\tlat_loss: 1.022471\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.082279\tcls_loss: 0.081046\tk_loss: 0.005257\tk: 0.072505\tlat_loss: 1.161187\t\n",
            "Validation (source) -> cls_loss: 0.101648\taccuracy: 97.1467%\n",
            "Validation (target) -> cls_loss: 1.010113\taccuracy: 69.9780%\n",
            "Epoch 17 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.081740\tcls_loss: 0.080627\tk_loss: 0.005266\tk: 0.072566\tlat_loss: 1.041247\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.022535\tcls_loss: 0.021164\tk_loss: 0.005324\tk: 0.072964\tlat_loss: 1.297706\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.091624\tcls_loss: 0.090201\tk_loss: 0.005347\tk: 0.073125\tlat_loss: 1.349519\t\n",
            "Validation (source) -> cls_loss: 0.098117\taccuracy: 97.2267%\n",
            "Validation (target) -> cls_loss: 1.015158\taccuracy: 69.8683%\n",
            "Epoch 18 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.106702\tcls_loss: 0.105241\tk_loss: 0.005351\tk: 0.073153\tlat_loss: 1.387843\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.055647\tcls_loss: 0.054348\tk_loss: 0.005370\tk: 0.073278\tlat_loss: 1.225362\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.068016\tcls_loss: 0.066508\tk_loss: 0.005358\tk: 0.073201\tlat_loss: 1.434190\t\n",
            "Validation (source) -> cls_loss: 0.093388\taccuracy: 97.4067%\n",
            "Validation (target) -> cls_loss: 1.143237\taccuracy: 69.5390%\n",
            "Epoch 19 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.134730\tcls_loss: 0.133253\tk_loss: 0.005358\tk: 0.073198\tlat_loss: 1.403306\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.101958\tcls_loss: 0.100629\tk_loss: 0.005388\tk: 0.073403\tlat_loss: 1.255974\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.097657\tcls_loss: 0.096493\tk_loss: 0.005447\tk: 0.073801\tlat_loss: 1.090030\t\n",
            "Validation (source) -> cls_loss: 0.095014\taccuracy: 97.3067%\n",
            "Validation (target) -> cls_loss: 0.751365\taccuracy: 75.3019%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 20 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.073968\tcls_loss: 0.072824\tk_loss: 0.005452\tk: 0.073836\tlat_loss: 1.071033\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.117755\tcls_loss: 0.116327\tk_loss: 0.005471\tk: 0.073965\tlat_loss: 1.354322\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.037156\tcls_loss: 0.035887\tk_loss: 0.005481\tk: 0.074031\tlat_loss: 1.194377\t\n",
            "Validation (source) -> cls_loss: 0.081974\taccuracy: 97.7200%\n",
            "Validation (target) -> cls_loss: 0.681812\taccuracy: 78.4852%\n",
            "Best model updated and saved at \"best_model.pt\"\n",
            "Epoch 21 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.028989\tcls_loss: 0.027550\tk_loss: 0.005482\tk: 0.074041\tlat_loss: 1.364566\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.063151\tcls_loss: 0.061790\tk_loss: 0.005500\tk: 0.074163\tlat_loss: 1.286213\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.121077\tcls_loss: 0.119602\tk_loss: 0.005550\tk: 0.074498\tlat_loss: 1.400090\t\n",
            "Validation (source) -> cls_loss: 0.080660\taccuracy: 97.7200%\n",
            "Validation (target) -> cls_loss: 0.938408\taccuracy: 69.7036%\n",
            "Epoch 22 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.071066\tcls_loss: 0.069821\tk_loss: 0.005554\tk: 0.074525\tlat_loss: 1.170562\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.059455\tcls_loss: 0.058013\tk_loss: 0.005582\tk: 0.074716\tlat_loss: 1.367119\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.128555\tcls_loss: 0.127165\tk_loss: 0.005626\tk: 0.075006\tlat_loss: 1.314706\t\n",
            "Validation (source) -> cls_loss: 0.075130\taccuracy: 97.9067%\n",
            "Validation (target) -> cls_loss: 1.116798\taccuracy: 70.5818%\n",
            "Epoch 23 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.031632\tcls_loss: 0.030227\tk_loss: 0.005631\tk: 0.075038\tlat_loss: 1.330015\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.066537\tcls_loss: 0.065301\tk_loss: 0.005679\tk: 0.075357\tlat_loss: 1.161004\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.074620\tcls_loss: 0.073333\tk_loss: 0.005716\tk: 0.075605\tlat_loss: 1.212066\t\n",
            "Validation (source) -> cls_loss: 0.087478\taccuracy: 97.7000%\n",
            "Validation (target) -> cls_loss: 0.826888\taccuracy: 76.4544%\n",
            "Epoch 24 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.059233\tcls_loss: 0.057905\tk_loss: 0.005720\tk: 0.075633\tlat_loss: 1.252085\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.043062\tcls_loss: 0.041685\tk_loss: 0.005773\tk: 0.075978\tlat_loss: 1.300708\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.020679\tcls_loss: 0.019585\tk_loss: 0.005826\tk: 0.076325\tlat_loss: 1.018013\t\n",
            "Validation (source) -> cls_loss: 0.090019\taccuracy: 97.5133%\n",
            "Validation (target) -> cls_loss: 0.861924\taccuracy: 72.2832%\n",
            "Epoch 25 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.090724\tcls_loss: 0.089790\tk_loss: 0.005831\tk: 0.076363\tlat_loss: 0.857099\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.032162\tcls_loss: 0.030786\tk_loss: 0.005902\tk: 0.076823\tlat_loss: 1.298720\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.066232\tcls_loss: 0.064904\tk_loss: 0.005985\tk: 0.077363\tlat_loss: 1.250449\t\n",
            "Validation (source) -> cls_loss: 0.077582\taccuracy: 97.9067%\n",
            "Validation (target) -> cls_loss: 0.994013\taccuracy: 73.4907%\n",
            "Epoch 26 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.061992\tcls_loss: 0.060603\tk_loss: 0.005989\tk: 0.077388\tlat_loss: 1.311543\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.068661\tcls_loss: 0.067599\tk_loss: 0.006025\tk: 0.077619\tlat_loss: 0.983993\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.082205\tcls_loss: 0.080866\tk_loss: 0.006043\tk: 0.077739\tlat_loss: 1.261208\t\n",
            "Validation (source) -> cls_loss: 0.074122\taccuracy: 98.0400%\n",
            "Validation (target) -> cls_loss: 1.091721\taccuracy: 70.8013%\n",
            "Epoch 27 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.033803\tcls_loss: 0.032382\tk_loss: 0.006043\tk: 0.077736\tlat_loss: 1.343337\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.093744\tcls_loss: 0.092401\tk_loss: 0.006093\tk: 0.078058\tlat_loss: 1.264796\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.019577\tcls_loss: 0.018033\tk_loss: 0.006171\tk: 0.078558\tlat_loss: 1.464808\t\n",
            "Validation (source) -> cls_loss: 0.078892\taccuracy: 97.8333%\n",
            "Validation (target) -> cls_loss: 1.047988\taccuracy: 72.2832%\n",
            "Epoch 28 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.022655\tcls_loss: 0.021055\tk_loss: 0.006183\tk: 0.078633\tlat_loss: 1.520741\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.018227\tcls_loss: 0.016854\tk_loss: 0.006248\tk: 0.079045\tlat_loss: 1.294367\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.023115\tcls_loss: 0.021660\tk_loss: 0.006303\tk: 0.079391\tlat_loss: 1.376146\t\n",
            "Validation (source) -> cls_loss: 0.072146\taccuracy: 97.9867%\n",
            "Validation (target) -> cls_loss: 1.119083\taccuracy: 71.4599%\n",
            "Epoch 29 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.055720\tcls_loss: 0.054321\tk_loss: 0.006314\tk: 0.079459\tlat_loss: 1.319661\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.035350\tcls_loss: 0.034200\tk_loss: 0.006353\tk: 0.079704\tlat_loss: 1.070993\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.030908\tcls_loss: 0.029644\tk_loss: 0.006356\tk: 0.079723\tlat_loss: 1.184933\t\n",
            "Validation (source) -> cls_loss: 0.076306\taccuracy: 97.8933%\n",
            "Validation (target) -> cls_loss: 0.950505\taccuracy: 72.5027%\n",
            "Epoch 30 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.086585\tcls_loss: 0.085323\tk_loss: 0.006355\tk: 0.079718\tlat_loss: 1.181637\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.055909\tcls_loss: 0.054581\tk_loss: 0.006378\tk: 0.079865\tlat_loss: 1.247760\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.046538\tcls_loss: 0.045261\tk_loss: 0.006413\tk: 0.080082\tlat_loss: 1.196251\t\n",
            "Validation (source) -> cls_loss: 0.075576\taccuracy: 97.9733%\n",
            "Validation (target) -> cls_loss: 0.846236\taccuracy: 73.2711%\n",
            "Epoch 31 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.022604\tcls_loss: 0.021215\tk_loss: 0.006416\tk: 0.080102\tlat_loss: 1.309223\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.037681\tcls_loss: 0.036466\tk_loss: 0.006437\tk: 0.080230\tlat_loss: 1.135643\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.022351\tcls_loss: 0.020974\tk_loss: 0.006437\tk: 0.080233\tlat_loss: 1.296243\t\n",
            "Validation (source) -> cls_loss: 0.070413\taccuracy: 98.0133%\n",
            "Validation (target) -> cls_loss: 1.135524\taccuracy: 68.6059%\n",
            "Epoch 32 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.065540\tcls_loss: 0.064221\tk_loss: 0.006438\tk: 0.080239\tlat_loss: 1.239323\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.043473\tcls_loss: 0.042196\tk_loss: 0.006429\tk: 0.080180\tlat_loss: 1.196963\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.017515\tcls_loss: 0.015998\tk_loss: 0.006442\tk: 0.080263\tlat_loss: 1.437093\t\n",
            "Validation (source) -> cls_loss: 0.075890\taccuracy: 97.8867%\n",
            "Validation (target) -> cls_loss: 1.038028\taccuracy: 70.6915%\n",
            "Epoch 33 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.089589\tcls_loss: 0.088137\tk_loss: 0.006443\tk: 0.080266\tlat_loss: 1.371132\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.015438\tcls_loss: 0.014141\tk_loss: 0.006478\tk: 0.080487\tlat_loss: 1.216295\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.082194\tcls_loss: 0.081115\tk_loss: 0.006516\tk: 0.080724\tlat_loss: 0.998398\t\n",
            "Validation (source) -> cls_loss: 0.075055\taccuracy: 97.8533%\n",
            "Validation (target) -> cls_loss: 0.838883\taccuracy: 74.3139%\n",
            "Epoch 34 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.040041\tcls_loss: 0.038758\tk_loss: 0.006521\tk: 0.080755\tlat_loss: 1.202281\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.026086\tcls_loss: 0.024883\tk_loss: 0.006537\tk: 0.080851\tlat_loss: 1.122132\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.083259\tcls_loss: 0.081974\tk_loss: 0.006557\tk: 0.080974\tlat_loss: 1.204036\t\n",
            "Validation (source) -> cls_loss: 0.072513\taccuracy: 98.1267%\n",
            "Validation (target) -> cls_loss: 0.887221\taccuracy: 72.9967%\n",
            "Epoch 35 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.050456\tcls_loss: 0.049200\tk_loss: 0.006565\tk: 0.081025\tlat_loss: 1.175524\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.015736\tcls_loss: 0.014402\tk_loss: 0.006598\tk: 0.081230\tlat_loss: 1.253016\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.041991\tcls_loss: 0.040700\tk_loss: 0.006631\tk: 0.081429\tlat_loss: 1.210308\t\n",
            "Validation (source) -> cls_loss: 0.071071\taccuracy: 98.0800%\n",
            "Validation (target) -> cls_loss: 0.956843\taccuracy: 70.3622%\n",
            "Epoch 36 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.030575\tcls_loss: 0.029266\tk_loss: 0.006636\tk: 0.081462\tlat_loss: 1.227061\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.030038\tcls_loss: 0.028855\tk_loss: 0.006662\tk: 0.081620\tlat_loss: 1.100684\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.009816\tcls_loss: 0.008230\tk_loss: 0.006685\tk: 0.081765\tlat_loss: 1.503971\t\n",
            "Validation (source) -> cls_loss: 0.073193\taccuracy: 98.1400%\n",
            "Validation (target) -> cls_loss: 0.802003\taccuracy: 75.2470%\n",
            "Epoch 37 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.045049\tcls_loss: 0.043514\tk_loss: 0.006686\tk: 0.081771\tlat_loss: 1.453216\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.052769\tcls_loss: 0.051429\tk_loss: 0.006693\tk: 0.081809\tlat_loss: 1.258523\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.019585\tcls_loss: 0.018172\tk_loss: 0.006714\tk: 0.081941\tlat_loss: 1.331090\t\n",
            "Validation (source) -> cls_loss: 0.065971\taccuracy: 98.1800%\n",
            "Validation (target) -> cls_loss: 0.934015\taccuracy: 72.7223%\n",
            "Epoch 38 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.113923\tcls_loss: 0.112611\tk_loss: 0.006720\tk: 0.081974\tlat_loss: 1.230732\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.073180\tcls_loss: 0.071833\tk_loss: 0.006749\tk: 0.082154\tlat_loss: 1.264051\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.008248\tcls_loss: 0.006853\tk_loss: 0.006780\tk: 0.082338\tlat_loss: 1.311815\t\n",
            "Validation (source) -> cls_loss: 0.069627\taccuracy: 98.1133%\n",
            "Validation (target) -> cls_loss: 1.021183\taccuracy: 71.7344%\n",
            "Epoch 39 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.022097\tcls_loss: 0.020673\tk_loss: 0.006783\tk: 0.082356\tlat_loss: 1.342338\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.030969\tcls_loss: 0.029913\tk_loss: 0.006804\tk: 0.082488\tlat_loss: 0.974205\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.038894\tcls_loss: 0.037619\tk_loss: 0.006826\tk: 0.082622\tlat_loss: 1.192337\t\n",
            "Validation (source) -> cls_loss: 0.071364\taccuracy: 98.0533%\n",
            "Validation (target) -> cls_loss: 0.801731\taccuracy: 74.4786%\n",
            "Epoch 40 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.019552\tcls_loss: 0.018459\tk_loss: 0.006831\tk: 0.082648\tlat_loss: 1.010435\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.098066\tcls_loss: 0.096951\tk_loss: 0.006909\tk: 0.083120\tlat_loss: 1.031510\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.011568\tcls_loss: 0.010307\tk_loss: 0.006910\tk: 0.083125\tlat_loss: 1.178373\t\n",
            "Validation (source) -> cls_loss: 0.062522\taccuracy: 98.2800%\n",
            "Validation (target) -> cls_loss: 0.810234\taccuracy: 75.8507%\n",
            "Epoch 41 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.032576\tcls_loss: 0.031388\tk_loss: 0.006908\tk: 0.083117\tlat_loss: 1.104653\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.019315\tcls_loss: 0.018191\tk_loss: 0.006952\tk: 0.083378\tlat_loss: 1.041041\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.133234\tcls_loss: 0.132090\tk_loss: 0.006948\tk: 0.083355\tlat_loss: 1.060978\t\n",
            "Validation (source) -> cls_loss: 0.067865\taccuracy: 98.0733%\n",
            "Validation (target) -> cls_loss: 0.852922\taccuracy: 76.7289%\n",
            "Epoch 42 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.041577\tcls_loss: 0.040370\tk_loss: 0.006950\tk: 0.083364\tlat_loss: 1.123812\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.006493\tcls_loss: 0.005509\tk_loss: 0.006984\tk: 0.083570\tlat_loss: 0.899830\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.009225\tcls_loss: 0.008071\tk_loss: 0.007012\tk: 0.083735\tlat_loss: 1.069763\t\n",
            "Validation (source) -> cls_loss: 0.067401\taccuracy: 98.1533%\n",
            "Validation (target) -> cls_loss: 0.990533\taccuracy: 69.9780%\n",
            "Epoch 43 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.044172\tcls_loss: 0.042989\tk_loss: 0.007019\tk: 0.083779\tlat_loss: 1.099880\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.105517\tcls_loss: 0.104363\tk_loss: 0.007095\tk: 0.084229\tlat_loss: 1.070097\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.016997\tcls_loss: 0.015994\tk_loss: 0.007231\tk: 0.085033\tlat_loss: 0.917525\t\n",
            "Validation (source) -> cls_loss: 0.063456\taccuracy: 98.2067%\n",
            "Validation (target) -> cls_loss: 0.833647\taccuracy: 72.6674%\n",
            "Epoch 44 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.104051\tcls_loss: 0.103041\tk_loss: 0.007247\tk: 0.085132\tlat_loss: 0.925291\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.053316\tcls_loss: 0.052135\tk_loss: 0.007324\tk: 0.085581\tlat_loss: 1.095294\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.027515\tcls_loss: 0.026644\tk_loss: 0.007357\tk: 0.085774\tlat_loss: 0.785793\t\n",
            "Validation (source) -> cls_loss: 0.059780\taccuracy: 98.3733%\n",
            "Validation (target) -> cls_loss: 0.758426\taccuracy: 78.6498%\n",
            "Epoch 45 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.135746\tcls_loss: 0.134794\tk_loss: 0.007354\tk: 0.085754\tlat_loss: 0.865547\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.014818\tcls_loss: 0.013719\tk_loss: 0.007439\tk: 0.086250\tlat_loss: 1.012740\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.030269\tcls_loss: 0.029246\tk_loss: 0.007592\tk: 0.087133\tlat_loss: 0.935502\t\n",
            "Validation (source) -> cls_loss: 0.068114\taccuracy: 97.9800%\n",
            "Validation (target) -> cls_loss: 0.845220\taccuracy: 74.8628%\n",
            "Epoch 46 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.058568\tcls_loss: 0.057618\tk_loss: 0.007603\tk: 0.087197\tlat_loss: 0.863245\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.042907\tcls_loss: 0.041737\tk_loss: 0.007672\tk: 0.087589\tlat_loss: 1.082313\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.041155\tcls_loss: 0.040155\tk_loss: 0.007766\tk: 0.088126\tlat_loss: 0.911897\t\n",
            "Validation (source) -> cls_loss: 0.060701\taccuracy: 98.1400%\n",
            "Validation (target) -> cls_loss: 0.976205\taccuracy: 69.3743%\n",
            "Epoch 47 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.102963\tcls_loss: 0.101903\tk_loss: 0.007767\tk: 0.088132\tlat_loss: 0.971363\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.096093\tcls_loss: 0.094892\tk_loss: 0.007836\tk: 0.088521\tlat_loss: 1.112685\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.009683\tcls_loss: 0.008487\tk_loss: 0.007926\tk: 0.089025\tlat_loss: 1.107440\t\n",
            "Validation (source) -> cls_loss: 0.067084\taccuracy: 98.1333%\n",
            "Validation (target) -> cls_loss: 0.915995\taccuracy: 71.8990%\n",
            "Epoch 48 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.034302\tcls_loss: 0.033224\tk_loss: 0.007929\tk: 0.089043\tlat_loss: 0.988854\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.028823\tcls_loss: 0.027631\tk_loss: 0.007930\tk: 0.089050\tlat_loss: 1.103337\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.065721\tcls_loss: 0.064819\tk_loss: 0.007936\tk: 0.089082\tlat_loss: 0.812942\t\n",
            "Validation (source) -> cls_loss: 0.062014\taccuracy: 98.1200%\n",
            "Validation (target) -> cls_loss: 0.876282\taccuracy: 73.7651%\n",
            "Epoch 49 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.034885\tcls_loss: 0.034022\tk_loss: 0.007934\tk: 0.089074\tlat_loss: 0.773568\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.042060\tcls_loss: 0.040902\tk_loss: 0.007999\tk: 0.089435\tlat_loss: 1.068539\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.028024\tcls_loss: 0.026958\tk_loss: 0.008027\tk: 0.089592\tlat_loss: 0.977145\t\n",
            "Validation (source) -> cls_loss: 0.056515\taccuracy: 98.3800%\n",
            "Validation (target) -> cls_loss: 0.975643\taccuracy: 71.2953%\n",
            "Epoch 50 --------\n",
            "Train -> [    0/ 5504 (0%)]\tloss: 0.017396\tcls_loss: 0.016326\tk_loss: 0.008028\tk: 0.089596\tlat_loss: 0.979977\t\n",
            "Train -> [ 2560/ 5504 (47%)]\tloss: 0.053844\tcls_loss: 0.052635\tk_loss: 0.008049\tk: 0.089718\tlat_loss: 1.118770\t\n",
            "Train -> [ 5120/ 5504 (93%)]\tloss: 0.040932\tcls_loss: 0.039869\tk_loss: 0.008070\tk: 0.089835\tlat_loss: 0.973456\t\n",
            "Validation (source) -> cls_loss: 0.056095\taccuracy: 98.4400%\n",
            "Validation (target) -> cls_loss: 0.986516\taccuracy: 70.5818%\n",
            "Test (source) -> cls_loss: 0.074613\taccuracy: 97.9900%\n",
            "Test (target) -> cls_loss: 0.778690\taccuracy: 74.7882%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('all_loss_train.npy', all_loss_train)\n",
        "np.save('all_loss_val.npy', all_loss_val)\n",
        "np.save('all_loss_test.npy', all_loss_test)\n",
        "\n",
        "plot_losses(\n",
        "    list(np.mean(all_loss_train, axis=0).T),\n",
        "    loss_labels_train,\n",
        "    ylabel='Loss',\n",
        "    xlabel='Epoch',\n",
        "    title='Training'\n",
        ")\n",
        "plot_losses(\n",
        "    list(np.mean(all_loss_val, axis=0).T),\n",
        "    loss_labels_val,\n",
        "    ylabel='Loss',\n",
        "    xlabel='Epoch',\n",
        "    title='Validation'\n",
        ")\n",
        "print(np.mean(all_loss_test, axis=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        },
        "id": "SLgJpPZ48g-4",
        "outputId": "95907a7b-759d-4c4e-ad8f-86b402d03a0b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.04695541 0.98618    0.69996895 0.79003488]\n"
          ]
        }
      ]
    }
  ]
}